

- 视频链接：[Ilya Sutskever: Deep Learning | Lex Fridman Podcast #94](https://www.youtube.com/watch?v=13CZPWmke6A)
- 官方频道：[Lex Fridman](https://www.youtube.com/@lexfridman)
- 日期：2020年5月9日

### 讲座介绍

本篇内容整理自 Lex Fridman 播客第 94 期，访谈嘉宾为 OpenAI 联合创始人兼首席科学家 Ilya Sutskever。作为深度学习领域的关键人物和历史上被引用次数最多的计算机科学家之一，Sutskever 在这次对话中深入回顾了深度学习从早期概念到革命性突破（如 AlexNet）的发展历程，并分享了他对神经网络核心机制的深刻见解，包括反向传播、代价函数以及令人惊讶的过参数化模型的有效性。

访谈不仅局限于技术细节，还广泛探讨了不同机器学习范式（视觉、语言、强化学习）的异同与统一趋势，并对大型语言模型（特别是 GPT-2）的能力、局限性及其引发的伦理考量进行了讨论。Sutskever 进一步展望了通往通用人工智能（AGI）的可能路径，涉及推理、记忆、自博弈、模拟、意识以及至关重要的对齐与控制问题。

对话最后触及了更深层次的哲学思考，探讨了智能的本质、人类在未来 AI 发展中的角色以及生命的意义。

### 内容纲要

```
深度学习访谈：Ilya Sutskever
├── 深度学习革命的起源与早期直觉
│   ├── AlexNet 与 ImageNet 时刻
│   ├── 早期核心直觉：大网络 + 大数据 + 反向传播
│   ├── 对过参数化的看法与计算瓶颈的突破
│   └── 大脑的启发作用
├── 深度学习核心概念与机制
│   ├── 代价函数（Cost Function）的重要性与局限性（GANs）
│   ├── 反向传播（Backpropagation）的价值与生物学联系
│   ├── 人工神经网络与大脑的差异思考（脉冲、STDP）
│   ├── 循环神经网络（RNNs）及其潜力与局限
│   └── 深度学习成功的关键要素（再述：数据、算力、信念、基准）
├── 机器学习领域的比较与统一趋势
│   ├── 机器学习领域的内在统一性
│   ├── 视觉（Vision）与自然语言处理（NLP）的比较与融合可能
│   └── 强化学习（RL）的独特性与统一性展望
├── 深度学习的力量、未解之谜与前沿挑战
│   ├── 深度学习有效性的惊叹与被低估的现状
│   ├── 深度双重下降（Deep Double Descent）现象与解释
│   ├── 神经网络的推理（Reasoning）能力探讨
│   ├── 长期记忆、知识库与可解释性问题
│   └── “小电路/小程序”隐喻与可训练性的核心地位
├── 语言模型（含GPT-2）与伦理考量
│   ├── 大型语言模型的崛起与语义理解的涌现
│   ├── GPT-2 技术细节（Transformer 架构的重要性）
│   ├── 语言模型的未来方向（规模、主动学习）
│   └── AI 系统的分阶段发布与伦理责任
├── 通用人工智能（AGI）的探索之路
│   ├── 构建 AGI 的关键要素猜想（深度学习 + α）
│   ├── 自博弈（Self-play）的角色与价值
│   ├── 模拟（Simulation）的作用与“模拟到现实”的迁移
│   ├── 具身智能（Embodiment）与意识（Consciousness）的讨论
│   ├── AGI 智能的测试标准探讨
│   └── AGI 的控制与对齐（Alignment）问题
└── 哲学思考：智能、控制与生命意义
    ├── 与 AGI 的首次对话设想
    ├── 对人类控制 AGI 能力的信念
    ├── 权力、责任与理想的 AGI 治理模式
    ├── 对生命意义的看法
    └── 关于遗憾、成就与幸福来源的个人反思
```

---



# Lex Fridman 播客-94：对话 Ilya Sutskever



## **I. 深度学习革命的开端与核心直觉**

**Lex Fridman:** 你是著名的 AlexNet 论文的三位作者之一，与 Alex Krizhevsky 和 Geoff Hinton 共同署名。这篇论文可以说标志着引发深度学习革命的关键催化时刻。带我们回到那个时候，你当时对神经网络，对其表征能力的直觉是怎样的？或许你可以谈谈在接下来的几年直到今天，这十年来，你的这种直觉是如何演变的？

**Ilya Sutskever:** 是的，我可以回答这个问题。大约在 2010 年或 2011 年的某个时候，我在脑海中将两个事实联系了起来。

基本上，认识是这样的：在某个时候，我们意识到我们可以通过反向传播端到端地训练非常大——我不应该说“非常”大，按今天的标准它们很小——但规模大且深的神经网络。在某个时候，不同的人得到了这个结果，我也得到了这个结果。

我第一次意识到深度神经网络强大是在 2010 年，当时 James Martens 发明了 Hessian-free 优化器，他从零开始、无需预训练就端到端地训练了一个 10 层的神经网络。当那发生时，我想，就是它了。因为如果你能训练一个大的神经网络，一个大的神经网络就能表示非常复杂的函数。因为如果你有一个 10 层的神经网络，就好比你允许人脑运行若干毫秒——神经元放电很慢，所以在也许 100 毫秒内，你的神经元只放电 10 次，所以这也差不多像 10 层。而在 100 毫秒内，你可以完美地识别任何物体。

所以我当时就已经有了这个想法，我们需要在大量监督数据上训练一个非常大的神经网络，然后它必定会成功。因为我们可以找到最好的神经网络。而且也有理论说，如果你的数据量比参数多，你就不会过拟合——今天我们知道这个理论其实非常不完整，当你数据少于参数时你*会*过拟合，但肯定的是，如果你数据多于参数，你不会过拟合。

**Lex Fridman:** 所以神经网络被严重过度参数化的事实并没有让你气馁？你当时考虑的理论是，参数数量巨大也没关系？

**Ilya Sutskever:** 我的意思是，之前有一些证据表明情况还算可以，但主要的理论是，如果你有一个大数据集和一个大型神经网络，它就会工作。过度参数化并没有真正被视为一个大问题。我想，嗯，对于图像，你只需添加一些数据增强，就会没事的。

那么，任何疑虑来自哪里呢？主要的疑虑是，我们是否有足够的计算能力来用反向传播训练一个足够大的神经网络？我认为反向传播会奏效。不清楚的是，是否会有足够的算力来获得一个非常有说服力的结果。

然后在某个时候，Alex Krizhevsky 为训练卷积神经网络编写了那些快得惊人的 CUDA 内核，然后就是“砰”！我们决定，就这么干！拿下 ImageNet，它将成为最伟大的事情。

**Lex Fridman:** 你的直觉大部分是来自你和其他人的经验结果吗？比如，实际证明一段程序可以训练一个 10 层神经网络？还是有一些纸笔或白板上的思考和直觉？因为你刚才把一个 10 层的大型神经网络和大脑联系起来了。在你关于神经网络的直觉中，人脑是否起到了构建直觉的作用？

**Ilya Sutskever:** 当然。我的意思是，你在人工神经网络和大脑之间做类比时必须精确，但毫无疑问，大脑是深度学习研究者巨大直觉和灵感的来源，从 60 年代的 Rosenblatt 一直到现在。比如，神经网络的整个概念就是直接受大脑启发的。你有像 McCulloch 和 Pitts 这样的人，他们说，嘿，大脑里有这些神经元，嘿，我们最近了解了计算机和自动机，我们能不能用计算机和自动机的一些想法来设计某种计算对象，既简单、可计算，又有点像大脑？然后他们发明了神经元。所以他们当时就受到了启发。然后你有了 Fukushima 和后来的 LeCun 的卷积神经网络，他们说，嘿，如果你限制神经网络的感受野，它将特别适用于图像，事实证明确实如此。

所以，有非常少量的例子表明，与大脑的类比是成功的。我想，嗯，一个人工神经元如果训练得足够好，可能和大脑（神经元）没有那么不同。所以，我们就假设它是，然后继续前进吧。

**Lex Fridman:** 现在我们处于深度学习非常成功的时代。让我们少眯着眼，睁大眼睛说，对你来说，人脑和人工神经网络之间有趣的差异是什么？我知道你可能不是神经科学家或神经生物学家，但粗略地说，在未来一二十年里，人脑和人工神经网络之间有哪些差异让你觉得有趣？

**Ilya Sutskever:** 这是一个好问题。人脑和我们的人工神经网络之间有趣的差异是什么？

我觉得今天的人工神经网络……我们都同意，在某些维度上，人脑的表现远远超过我们的模型。但我也认为，在某些方面，人工神经网络相对于大脑具有一些非常重要的优势。审视优势与劣势是找出重要差异的好方法。

大脑使用脉冲（spikes），这可能重要，也可能不重要。

**Lex Fridman:** 是的，这确实是个有趣的问题。你认为它重要吗？这是人工神经网络之间一个很大的架构差异。

**Ilya Sutskever:** 很难说，但我（对其重要性）的先验判断不是很高，我可以解释为什么。你知道，有些人对脉冲神经网络感兴趣，他们基本上发现，他们需要用脉冲来模拟非脉冲神经网络，这样才能让它们工作。如果你不用脉冲模拟非脉冲神经网络，它就不会工作，因为问题是，它凭什么工作呢？这又关联到关于反向传播和深度学习的问题。你有一个巨大的神经网络...

## **II. 深度学习的基本概念与机制**

**Ilya Sutskever:** ……为什么它应该能工作？学习规则为什么应该奏效？这根本不是一个不证自明的问题。特别是，比如说，如果你刚进入这个领域，读了非常早期的论文，你会说，嘿，人们说让我们构建神经网络，这是个好主意，因为大脑是神经网络。所以构建神经网络会有用。现在让我们弄清楚如何训练它们。应该有可能正确地训练它们，但是怎么做呢？

所以，重要的思想是代价函数（Cost Function）。这是一个重要的思想。代价函数是根据某种度量来衡量系统性能的一种方式。

**Lex Fridman:** 顺便问一下，这是一个难以想到的想法吗？以及“单一代价函数”这个想法有多重要？让我停顿一下思考。监督学习是一个难以形成的概念吗？

**Ilya Sutskever:** 我不知道。所有概念事后看来都非常容易。

**Lex Fridman:** 是的，现在看起来似乎微不足道。但我之所以这么问，是因为（后面我们会谈到）是否存在其他东西？是否存在不一定有代价函数的东西，也许有多个代价函数，或者动态代价函数，或者完全不同的架构？因为我们需要这样思考才能达到新的东西，对吧？

**Ilya Sutskever:** 所以，没有明确代价函数的好例子是 GANs（生成对抗网络）。在 GAN 中，你有一个博弈。所以你不是想优化一个代价函数——你知道你有一个算法（梯度下降）会优化代价函数，然后你可以根据它优化的目标来推理你的系统行为。对于 GAN，你说我有一个博弈，我将根据博弈的均衡来推理系统的行为。但这都是关于提出这些数学对象，帮助我们推理系统的行为，对吧？

**Lex Fridman:** 这真的很有趣。是的，GAN 是唯一一个……代价函数是从比较中涌现出来的。我不知道它是否有代价函数，我不知道谈论 GAN 的代价函数是否有意义。这有点像生物进化或经济的代价函数。你可以谈论它将趋向的区域，但我认为代价函数的类比不是最有用的。

**Lex Fridman:** 这非常有趣。所以如果进化并没有一个真正的代价函数，像我们数学概念中的那种代价函数，那么你认为深度学习中的代价函数在阻碍我们吗？你刚才提到代价函数是一个深刻的好想法。你认为这是一个好想法吗？你认为这是一个我们会超越的想法吗？自博弈（Self-play）在强化学习系统中开始触及这一点。

**Ilya Sutskever:** 没错，自博弈，还有围绕探索（Exploration）的想法，比如你试图采取让预测器惊讶的行动。

我是代价函数的忠实粉丝。我认为代价函数很棒，它们为我们服务得非常好。我认为只要我们能用代价函数做事，就应该这样做。你知道，也许有机会我们会想出另一种看待事物的深刻方式，其中代价函数不那么核心，但我不知道。我认为代价函数……我的意思是，我不会赌代价函数会消失。

**Lex Fridman:** 关于大脑，还有其他什么东西会让你想到，可能对我们设计人工神经网络有不同和有趣的启发？我们稍微谈到了脉冲。

**Ilya Sutskever:** 我的意思是，有一件事可能潜在有用。我认为神经科学家弄清楚了一些关于大脑学习规则的东西，我指的是脉冲时间依赖可塑性（Spike-Timing-Dependent Plasticity, STDP）。如果有人能在模拟中研究它，那会很好。

**Lex Fridman:** 等等，脉冲时间依赖可塑性？那是什么？

**Ilya Sutskever:** 它是一种特殊的学习规则，利用脉冲时序来决定如何更新突触。大概是这样：如果突触在神经元放电之前向神经元放电，那么它会加强这个突触；如果突触在神经元放电后不久向神经元放电，那么它会削弱这个突触。大致是这样，我有 90% 的把握是正确的。所以如果我这里说错了什么，别太生气。

**Lex Fridman:** 但你刚才说的时候听起来很聪明。但是时序，这是缺失的一点。时间动态没有被捕捉到。我觉得这像是大脑的一个基本属性，就是信号的时序。

**Ilya Sutskever:** 嗯，循环神经网络（Recurrent Neural Networks, RNNs）... 但你认为那... 我的意思是，那是一个非常粗糙、简化的... 那叫什么来着... 循环神经网络似乎有个时钟。似乎大脑是它的通用、连续版本，一种泛化，其中所有可能的时序都是可能的，并且在这些时序中包含了某些信息。你认为循环神经网络中的循环（Recurrence）...

**Lex Fridman:** ……能够捕捉到与大脑中神经元放电时序（这似乎对大脑很重要）相同的现象吗？

**Ilya Sutskever:** 我的意思是，我认为循环神经，循环神经网络非常了不起。我认为它们能做我们希望系统能做的任何事情。现在循环神经网络已经被 Transformer 超越了，但也许有一天它们会卷土重来，也许它们会回来，我们拭目以待。

**Lex Fridman:** 让我稍微偏个题问一下，你认为它们会回来吗？最近很多突破，我们稍后会谈到，在自然语言处理和语言建模方面，都是使用 Transformer，它不强调循环。你认为循环会卷土重来吗？

**Ilya Sutskever:** 嗯，某种形式的循环，我认为很有可能。用于处理序列的、通常意义上的循环神经网络，我认为也是可能的。

**Lex Fridman:** 对你来说，循环神经网络通常是指什么？我想，广义上说，什么是循环神经网络？

**Ilya Sutskever:** 你有一个神经网络，它维持一个高维的隐藏状态。然后当一个观测到达时，它通过其连接以某种方式更新其高维隐藏状态。

**Lex Fridman:** 你认为，你知道，这就像专家系统做的那样，对吧？符号 AI……知识库的增长，就是维护一个隐藏状态，即它的知识库，并通过顺序处理来增长它。你是否更广义地这样看待它？还是仅仅是我们今天思考的 LSTM 等具有特定门控单元的隐藏状态的更受限形式？

**Ilya Sutskever:** 我的意思是，隐藏状态技术上就是你描述的那样，进入 LSTM 或 RNN 内部的隐藏状态。但它应该包含什么……如果你想做专家系统的类比，我不是……你可以说知识存储在连接中，然后短期处理在隐藏状态中完成。

**Lex Fridman:** 可以这么说吗？是的。那么，有点……

**Ilya Sutskever:** 是的。

**Lex Fridman:** 你认为未来在神经网络内部构建大规模知识库是可能的吗？

**Ilya Sutskever:** 当然。

**Lex Fridman:** 我们先暂停一下这个自信的回答，因为我想探索一下。让我回到 ImageNet 的历史。正如你提到的，神经网络已经存在了几十年。

**Lex Fridman:** 你认为导致它们在 ImageNet 时刻及之后十年取得成功的关键思想是什么？

**Ilya Sutskever:** 好的。所以问题是，确保我没漏掉任何东西，过去十年深度学习成功的关键思想是什么？

**Lex Fridman:** 没错，即使深度学习背后的基本东西已经存在了更长时间。

**Ilya Sutskever:** 关于深度学习的关键思想，或者更确切地说，在深度学习开始成功之前的关键事实是，它被低估了。从事机器学习的人根本不认为神经网络能做多少事情。人们不相信大型神经网络可以被训练。人们认为……嗯，当时机器学习领域关于什么是正确的方法等有很多争论。人们争论不休，因为没有……没有办法获得确凿的事实。我的意思是，没有真正困难的基准测试，如果你在上面做得非常好，那么你就可以说：“看，这是我的系统”。那时这个领域就变得更像是一个工程领域了。

就深度学习而言，直接回答问题，思想都已具备。缺失的是大量的监督数据和大量的计算能力。一旦你有了大量的监督数据和大量的计算能力，那么还需要第三样东西，那就是信念（Conviction）。信念是指，相信如果你采用已经存在的正确的东西，并将其与大量数据和大量计算混合在一起，它实际上会奏效。所以，这就是缺失的部分。你需要数据，你需要计算能力（以 GPU 的形式出现），你需要信念来认识到你需要将它们结合在一起。

**Lex Fridman:** 这真的很有趣。所以，我想计算能力和监督数据的存在使得经验证据能够说服计算机科学界的大多数人。我想有一个关键时刻，是 Jitendra Malik 和 Alyosha Efros，他们当时非常怀疑，对吧？然后是 Geoffrey Hinton，他则完全不怀疑。然后有一个说服的时刻，我认为 ImageNet 就扮演了那个角色。

**Ilya Sutskever:** 没错。他们代表了计算机视觉社区的巨头，有点像巫师们聚在一起，然后突然之间发生了转变。

**Lex Fridman:** 光有想法和算力是不够的，还需要它来说服当时存在的怀疑论。有趣的是，人们在几十年里就是不相信。

**Ilya Sutskever:** 是的。嗯，但还不止于此。这样说听起来好像是，“嗯，那些不相信的傻瓜们，他们错过了什么？”但实际上，情况很混乱，因为神经网络在任何事情上都确实不起作用，而且它们在几乎任何方面都不是最好的方法。所以说，“是的，这东西没有任何进展”是非常理性的。这就是为什么你需要这些非常困难的任务，它们能产生无可辩驳的证据。这就是我们取得进步的方式。这就是为什么这个领域今天在进步，因为我们有这些代表真正进步的困难基准。因此，这就是为什么我们能够避免无休止的争论。

## **III. 不同学习领域的比较与统一**

**Lex Fridman:** 令人难以置信的是，你贡献了 AI 领域近期一些最重要的思想，在计算机视觉、自然语言处理、强化学习，以及介于两者之间的一切领域——也许除了 GANs？可能没有你没触及过的主题——当然还有深度学习的基础科学。对你来说，视觉、语言和强化学习中的“行动”作为学习问题，它们之间的区别是什么？它们的共同点又是什么？你认为它们都是相互关联的，还是需要不同方法的根本不同的领域？

**Ilya Sutskever:** 好的，这是个好问题。机器学习是一个具有高度统一性的领域，极大的统一性。

**Lex Fridman:** 你说的统一性是指什么？

**Ilya Sutskever:** 比如思想的重叠，原则的重叠。事实上，只有一两个或三个非常非常简单的原则，然后它们以几乎相同的方式应用于不同的模态、不同的问题。这就是为什么今天当有人写一篇关于改进视觉深度学习优化的论文时，它也会改进不同的 NLP 应用，也会改进不同的强化学习应用。

强化学习……我会说，计算机视觉和 NLP 今天彼此非常相似。它们的区别在于架构略有不同，我们在 NLP 中使用 Transformer，在视觉中使用卷积神经网络。但也有可能有一天这会改变，一切都会用单一架构统一起来。因为如果你回到几年前，在自然语言处理领域，对于每一个微小的问题都有大量的架构，每个小问题都有自己的架构。今天，对于所有这些不同的任务，只有一个 Transformer。如果你再往前追溯，你会发现更加碎片化，AI 中的每个小问题都有自己的小专业化和小技能集合，人们需要知道如何工程化特征。现在，这一切都被深度学习所包容，我们有了这种统一。

所以我期望视觉也会与自然语言统一起来，或者更确切地说，我不应该说期望，我认为这是可能的。我不想太确定，因为我认为卷积神经网络在计算上非常高效。

RL（强化学习）是不同的。RL 确实需要稍微不同的技术，因为你确实需要采取行动，你确实需要做一些关于探索的事情，你的方差要大得多。但我认为即使在那里也有很多统一性。例如，我预计在某个时候，RL 和监督学习之间会有更广泛的统一，某种程度上 RL 会做出决策来让监督学习进行得更好。我设想它会是一个巨大的黑盒子，你只需要把所有东西铲进去，它就能弄清楚如何处理你铲进去的任何东西。

**Lex Fridman:** 我的意思是，强化学习几乎结合了语言和视觉的某些方面。有你应该利用的长期记忆元素，也有非常丰富的感官空间元素。所以看起来它像是两者的并集或类似的东西。

**Ilya Sutskever:** 我会稍微不同地说。我会说强化学习既不是视觉也不是语言，但它自然地与两者接口和集成。

**Lex Fridman:** 你认为行动是根本不同的吗？是的，关于学习行动的策略（Policy），有什么独特之处？

**Ilya Sutskever:** 嗯，举个例子，当你学习行动时，你从根本上处于一个非稳态（non-stationary）的世界，因为随着你的行动改变，你看到的事物开始改变，你以不同的方式体验世界。这与更传统的静态问题不同，在静态问题中，你至少有一个分布，你只是将模型应用于该分布。

**Lex Fridman:** 你认为这是一个根本不同的问题，还是只是一个更困难的泛化问题？是理解问题的泛化吗？

**Ilya Sutskever:** 我的意思是，这几乎是一个定义的问题。肯定有大量的共同点，毫无疑问。你计算梯度，你尝试……你在两种情况下都尝试近似梯度。在强化学习的情况下，你有一些工具来减少梯度的方差，你就这样做。有很多共同点。你在两种情况下都使用相同的神经网络。你计算梯度，你在两种情况下都应用 Adam 优化器。所以，我的意思是，肯定有很多共同点。但是有一些小的差异，并非完全不重要。这真的取决于你的观点，你选择什么参考框架，你观察这些问题时想放大还是缩小多少。

**Lex Fridman:** 你认为哪个问题更难？像诺姆·乔姆斯基这样的人认为语言是万物的根本，它支撑着一切。你认为语言理解比视觉场景理解更难，还是反之？

**Ilya Sutskever:** 我认为问一个问题是否“难”有点不对。我认为这个问题有点问题，我想解释为什么。一个问题“难”意味着什么？无趣的、愚蠢的答案是：有一个基准，有一个人类在该基准上的表现水平，以及达到人类水平所需的努力。

**Lex Fridman:** 从达到某个非常好的基准上的人类水平需要多少努力的角度来看……是的，像某些……我明白你的意思。

**Ilya Sutskever:** 我想说的是，很多时候取决于……一旦你解决了一个问题，它就不再难了，这总是真的。所以某件事是否难，取决于我们今天的工具能做什么。所以，你知道，你说今天，真正的人类水平的语言理解和视觉感知是困难的，因为没有办法在未来三个月内完全解决这个问题。所以我同意这个说法。除此之外，我的猜测和你的一样好，我不知道。

**Lex Fridman:** 哦，好吧。所以你对于语言理解有多难没有基本的直觉？

**Ilya Sutskever:** 我想……我知道了，我改变主意了。假设语言可能会更难。我的意思是，这取决于你如何定义它。比如，如果你指的是绝对顶尖的、100% 的语言理解，我会选语言。

但是，如果我给你看一张写着字母的纸……你明白我的意思吗？你有一个视觉系统，你说它是最好的人类水平视觉系统。我打开一本书，给你看字母。它会理解这些字母如何组成单词、句子和意义吗？这是视觉问题的一部分吗？视觉在哪里结束，语言又在哪里开始？

**Lex Fridman:** 是的，乔姆斯基会说它始于语言。所以视觉只是我们大脑中某种结构和基本思想层次的一个小例子，这种结构通过语言来表达。但是……

**Ilya Sutskever:** ……视觉在哪里停止，语言又在哪里开始？这真是一个有趣的问题。

一种可能性是，如果不基本上使用同一种系统，就不可能在图像或语言中实现真正深刻的理解。所以你会免费得到另一个。

**Lex Fridman:** 我认为这很有可能，是的。如果我们能得到一个，我们的机器学习可能足够好，以至于我们能得到另一个。但不是 100%，我不完全确定。而且我认为很多真的取决于你的定义。比如“完美视觉”的定义。因为真的，你知道，阅读是视觉，但它应该算吗？

**Lex Fridman:** 对我来说……所以我的定义是，如果一个系统看了一张图片，然后这个系统看了一段文字，然后告诉我一些关于它的事情，并且我真的印象深刻……

**Ilya Sutskever:** （印象深刻是）相对的。你会印象深刻半小时，然后你会说，“嗯，我的意思是，所有的系统都这样做。但它们不做的是这个……”

**Lex Fridman:** 是的，但我对人类没有这种感觉。人类持续地让我印象深刻。

**Ilya Sutskever:** 这是真的吗？嗯，那些……好吧，我是单一伴侣制的支持者，所以我喜欢和某人结婚、相伴几十年的想法。所以我相信，是的，有可能让某人持续地给你带来愉悦的、有趣的、机智的新想法。朋友……

**Lex Fridman:** 是的，我认为是的。他们持续地让你惊讶。

**Ilya Sutskever:** 惊讶……

**Lex Fridman:** 嗯……你知道，那种随机性的注入似乎是……似乎是一种很好的持续灵感的来源。比如机智、幽默……

**Ilya Sutskever:** 是的。

**Lex Fridman:** 我想是的。那……那会是一个……这是一个非常主观的测试，但我想如果你房间里有足够多的人……

**Ilya Sutskever:** 是的，我明白你的意思了。是的，我觉得我误解了你说的“让你印象深刻”的意思。我以为你是指用它的智能，用它理解图像有多好来打动你。我以为你的意思是，“我要给它看一张非常复杂的图片，它能正确理解”，然后你会说，“哇，这真酷。2020 年 1 月的系统还做不到这个。”

**Lex Fridman:** 是的，不。我认为这一切都归结为，比如人们在互联网上点赞的原因，就是因为它让他们发笑。所以像是幽默或机智。

**Ilya Sutskever:** 是的。或者洞察力。我相信我们也会得到那个的。

## **IV. 深度学习的力量、奥秘与挑战**

**Lex Fridman:** 抱歉问个浪漫化的问题，回顾过去，对你来说，在深度学习或广义 AI 中，你遇到的最美妙或最令人惊讶的想法是什么？

**Ilya Sutskever:** 我认为深度学习最美妙的事情在于它*竟然真的有效*。我是认真的，因为你有这些想法，你有小小的神经网络，你有反向传播算法，然后你有一些理论，比如，“这有点像大脑，所以也许你把它做大，把神经网络做大，用大量数据训练它，那么它就能完成大脑所做的同样功能。” 结果证明这是真的。这太疯狂了。

现在我们就训练这些神经网络，你把它们做得更大，它们就持续变得更好。我觉得这难以置信。我觉得整个 AI 用神经网络这套东西能行得通，令人难以置信。

**Lex Fridman:** 你是否建立起了关于它为什么能行的直觉？有没有一些零散的直觉片段或洞察来解释为什么这整件事能行？

**Ilya Sutskever:** 我的意思是，有些……当然，我们知道优化……我们现在有很好的……你知道，我们有大量的经验……大量的经验理由相信优化在我们关心的几乎所有问题上都应该奏效。

**Lex Fridman:** 你有什么关于……你刚才说经验证据……你的大部分……

**Ilya Sutskever:** ……是经验证据让你信服吗？就像进化是经验性的一样，它向你展示，“看，这个进化过程似乎是设计能在其环境中生存的生物的好方法”，但它并没有真正让你洞察整个事物是如何运作的。

**Ilya Sutskever:** 我认为一个好的类比是物理学。你知道，你怎么说，“嘿，让我们做一些物理计算，提出一些新的物理理论，并做出一些预测。”但然后你必须进行实验。你知道，你必须进行实验，这很重要。这里有点类似，只是也许有时实验先于理论。但情况仍然如此，你知道，你有一些数据，你提出一些预测，你说，“是的，让我们做一个大的神经网络，让我们训练它，它将比以前任何东西都好得多。而且当你把它做得更大时，它实际上会继续变得更好。” 结果证明这是真的。这……这太棒了。当一个理论像这样被验证时，你知道，它不是一个数学理论，它更像是一个生物学理论，差不多。

所以我认为深度学习和生物学之间并非没有糟糕的类比。我会说，它就像生物学和物理学的几何平均数（geometric mean），那就是深度学习。

**Lex Fridman:** 生物学和物理学的几何平均数？我想我需要几个小时来理解这个。因为仅仅找到几何……仅仅找到……生物学代表的集合……

**Ilya Sutskever:** 嗯，生物学……在生物学中，事情非常复杂，理论非常非常……很难有好的预测性理论。而在物理学中，理论太好了。理论上，在物理学中，人们提出这些超精确的理论，做出这些惊人的预测。而在机器学习中……

**Lex Fridman:** ……有点介于两者之间。

**Ilya Sutskever:** 有点介于两者之间。但如果机器学习能以某种方式帮助我们发现两者的统一，而不是处于两者之间，那就太好了。

**Lex Fridman:** 但你说得对。你有点像在同时兼顾两者。那么，你认为神经网络中是否仍有尚未被发现的美妙而神秘的特性？

**Ilya Sutskever:** 当然。我认为我们仍然在**大规模地低估**深度学习。

**Lex Fridman:** 你认为它会是什么样子？比如，什么……

**Ilya Sutskever:** 如果我知道，我就已经去做了。

**Lex Fridman:** 是的。所以……但如果你看看过去十年的所有进展，我会说大部分……我会说有少数情况，出现了一些感觉像是真正新想法的东西。但总的来说，是每年我们都想，“好吧，深度学习就到这儿了。”不，它实际上走得更远。然后下一年，“好吧，现在……现在这已经是深度学习的顶峰了，我们真的到头了。”不，它走得更远。它每年都在不断走得更远。这意味着我们持续在低估它，持续不理解它。它总是有令人惊讶的特性。

**Lex Fridman:** 你认为取得进展越来越难了吗？

**Ilya Sutskever:** 这取决于我们指的是什么。我认为这个领域将在相当长的一段时间内继续取得非常稳健的进展。我认为对于个别研究人员，特别是那些正在做……研究的人来说，可能会更难，因为现在研究人员数量非常庞大。我认为如果你有大量的计算资源，那么你可以做出很多非常有趣的发现。但那样你就必须处理管理一个巨大的计算……一个巨大的计算集群、尝试实验的挑战。所以这有点难。

**Lex Fridman:** 我在问这些没人知道答案的问题，但你是我认识的最聪明的人之一，所以我会继续问。让我们想象一下未来 30 年深度学习领域发生的所有突破。你认为这些突破中的大部分能由一个人用一台电脑完成吗？在突破的……空间里？你认为计算能力和大规模努力会是必需的吗？

**Ilya Sutskever:** 我的意思是，我不能确定。当你说“一台电脑”时，你是指多大？

**Lex Fridman:** 你……你很聪明。我的意思是，一个……一个 GPU。

**Ilya Sutskever:** 我明白了。我认为这非常不可能。我认为这非常不可能。我认为有很多……深度学习的技术栈（stack）开始变得相当深了。如果你看一下，从最顶层的想法，到构建系统的工具，数据集，分布式编程，构建实际的集群，GPU 编程，把所有这些整合在一起。所以现在这个技术栈变得非常深。我认为对于单个人来说，在技术栈的每一层都达到世界级水平变得非常困难。

**Lex Fridman:** 那么像 Vladimir Vapnik 真正坚持的那样呢？采用 MNIST 数据集，并尝试从极少数例子中学习？也就是能够更有效地学习。你认为在那个领域会有突破吗？那可能不需要巨大的计算能力。

**Ilya Sutskever:** 我认为……我认为总的来说，将会有大量的突破不需要巨大的计算能力。所以也许我应该澄清一下。我认为有些突破将需要大量的计算能力。而且我认为构建真正能做事情的系统将需要巨大的计算能力。这一点很明显。如果你想做 X，而 X 需要一个巨大的神经网络，你就必须得到一个巨大的神经网络。但我认为，对于小团体和个人来说，仍然有很大的空间来完成非常重要的工作。

**Lex Fridman:** 也许……正好谈到深度学习科学这个话题，谈谈你最近发布的一篇论文，《深度双重下降：更大的模型和更多的数据有时会损害性能》（Deep Double Descent: Where Bigger Models and More Data Hurt）。我认为这是一篇非常有趣的论文。你能描述一下主要思想吗？

**Ilya Sutskever:** 是的，当然。事情是这样的，多年来，少数研究人员注意到，当你把神经网络做得更大时，它效果更好，这有点奇怪，似乎与统计学的思想相矛盾。然后一些人做了一个分析，表明实际上存在这个双重下降（double descent）的凸起。我们所做的是展示了双重下降发生在几乎所有实用的深度学习系统中。

**Lex Fridman:** 你能退一步解释一下吗？双重下降图的 X 轴和 Y 轴是什么？

**Ilya Sutskever:** 好的，很好。你可以这样做，你可以拿一个神经网络，然后你可以开始缓慢地增加它的大小，同时保持你的数据集固定。如果你缓慢增加神经网络的大小，并且你不做早停（early stopping）——这是一个非常重要的细节——那么当神经网络非常小的时候，你把它变大，你会得到性能的快速提升。然后你继续把它变大，在某个点性能会变差。并且它在恰好达到零训练误差，精确地零训练损失的点上变得最差。然后当你把它变得更大时，它又开始变得更好。

这有点反直觉，因为你会期望深度学习现象是单调的。很难确定这意味着什么，但它也在线性分类器的情况下发生。

直觉基本上可以归结为以下几点：当你……当你有一个大数据集和一个小模型时，那么微小的随机……基本上，什么是过拟合？过拟合是指你的模型以某种方式对训练数据集中微小的、随机的、不重要的东西非常敏感。

**Lex Fridman:** 精确地说，是训练数据集。

**Ilya Sutskever:** 精确地说。所以如果你有一个小模型，你有一个大数据集，可能有一些随机的东西，你知道，一些训练样本随机地在数据集中，而其他的可能不在。但是小模型对这种随机性有点不敏感，因为它是相同的……当它那么大时，关于模型几乎没有不确定性。

**Lex Fridman:** 好吧。所以对我来说，最基本层面上，最令人惊讶的事情是神经网络不总是很快就过拟合，在能够学到任何东西之前。巨大的参数数量……

**Ilya Sutskever:** 所以这里……有一种方式……好吧，也许……所以让我尝试给出解释，也许这会奏效。你有一个巨大的神经网络。假设你有一个巨大的神经网络，你有大量的参数。现在让我们假设一切都是线性的——虽然不是，但我们姑且这么假设。那么存在一个巨大的子空间，其中神经网络达到零误差。SGD（随机梯度下降）将会找到近似……没错，近似该子空间中范数（norm）最小的点。好的。并且也可以证明，在高维情况下，这个点对数据中的微小随机性不敏感。但是当数据的维度等于模型的维度时，那么所有数据集和模型之间存在一一对应关系。所以数据集的微小变化实际上会导致模型的大变化。这就是为什么性能会变差。这或多或少是最好的解释。

**Lex Fridman:** 那么对于模型来说，拥有更多参数，也就是比数据更大，会更好？

**Ilya Sutskever:** 没错。但前提是你没有真正停止。如果你引入早停或正则化，你可以让双重下降的凸起几乎完全消失。

**Lex Fridman:** 什么是早停？

**Ilya Sutskever:** 早停是指当你训练模型时，你监控你的测试集或验证集性能，然后在某个点验证性能开始变差时，你说，“好吧，让我们停止训练。” 如果你够好了，你就够好了。

**Lex Fridman:** 所以魔法发生在那个时刻之后？所以你不想做早停？

**Ilya Sutskever:** 嗯，如果你不做早停，你会得到一个非常……你会得到一个非常显著的双重下降。

**Lex Fridman:** 你对为什么会发生双重下降有什么直觉吗？哦抱歉，是早停吗？

**Ilya Sutskever:** 不，是双重下降。

**Lex Fridman:** 哦，是的。

**Ilya Sutskever:** 所以我尝试……看，直觉基本上是这样的：当数据集具有与模型一样多的自由度时，它们之间存在一一对应关系。因此，数据集的微小变化会导致模型发生显著变化。所以你的模型对所有的随机性都非常敏感，它无法丢弃它。然而，事实证明，当你的数据远多于参数，或者参数远多于数据时，得到的解将对数据集的微小变化不敏感。

**Lex Fridman:** 所以它能够……说得很好……丢弃微小的变化，随机性……

**Ilya Sutskever:** 正是，那些你不想要的虚假相关性。

**Lex Fridman:** Geoff Hinton 建议我们需要抛弃反向传播。我们已经稍微谈到过这个，但是……

**Lex Fridman:** 他建议我们直接扔掉反向传播，重新开始。当然，这其中有些有点……幽默成分。但你怎么看？训练神经网络的替代方法可能是什么？

**Ilya Sutskever:** 嗯，他确切说的是，如果你在 大脑中找不到反向传播，那么看看我们是否能从大脑的学习方式中学到一些东西是值得的。但是反向传播非常有用，我们应该继续使用它。

**Lex Fridman:** 你是说，一旦我们发现了大脑的学习机制或该机制的任何方面，如果事实证明我们在大脑中找不到反向传播，我们也应该尝试在神经网络中实现它？

**Ilya Sutskever:** 如果我们在大脑中找不到反向传播的话。

**Lex Fridman:** 好吧。所以我想你的答案是……反向传播非常有用，我们为什么要抱怨呢？

**Ilya Sutskever:** 我的意思是，我个人是反向传播的忠实粉丝。我认为这是一个伟大的算法，因为它解决了一个极其根本的问题，那就是在某些约束条件下找到一个神经回路。而且我看不到这个问题会消失。所以这就是为什么我真的……我认为我们拥有与之截然不同的东西的可能性非常小。可能会发生，但我现在不会押注于此。

## **V. 语言模型、GPT-2与伦理考量**

**Lex Fridman:** 让我问一个更宏观的问题。你认为神经网络可以被用来进行推理（Reasoning）吗？

**Ilya Sutskever:** 为什么不呢？嗯，如果你看看，例如 AlphaGo 或 AlphaZero，AlphaZero 的神经网络下围棋——我们都同意围棋是一个需要推理的游戏——比 99.9% 的人类都要好。仅仅是神经网络，没有搜索。仅仅是神经网络本身。这难道没有给我们一个存在性证明，证明神经网络可以推理吗？

**Lex Fridman:** 稍微反驳和不同意一下。我们都同意围棋是推理吗？我想……我同意。我不认为这是微不足道的……所以，显然推理，就像智能一样，是一个……是一个模糊的灰色地带术语，有点……也许你不同意这一点。但是，是的，我认为它具有一些与推理相同的元素。推理几乎类似于搜索，对吧？有一个逐步考虑可能性的顺序元素，并在这些可能性的基础上以顺序方式构建，直到你得出某种见解。所以，是的，我猜下围棋有点像那样。当你有一个单一的神经网络在没有搜索的情况下这样做时，那有点像那样。所以在特定的受限环境中，存在一个类似于许多人称之为推理的过程的存在性证明。但更普遍的推理呢？在棋盘之外？

**Ilya Sutskever:** 还有一个存在性证明。

**Lex Fridman:** 哦，天哪。哪个？

**Ilya Sutskever:** 我们人类。

**Lex Fridman:** 是的。好吧。好吧。所以……你认为能够让神经网络进行推理的架构会与我们今天拥有的神经网络架构相似吗？

**Ilya Sutskever:** 我认为是这样。我认为……嗯，我不想做出过于确定的陈述。我认为，产生未来推理突破的神经网络很可能与今天存在的架构非常相似，这绝对是可能的。也许会更具循环性，也许会更深一些。但是……但是这些……这些神经网络是如此……如此地强大。它们为什么不能学会推理呢？人类可以推理，那么神经网络为什么不能呢？

**Lex Fridman:** 那么你认为我们看到的神经网络所做的事情是一种……只是一种弱推理吗？所以它不是一个根本不同的过程？这又是我们都不知道答案的事情。

**Ilya Sutskever:** 当涉及到我们的神经网络时，我会认为，我会说的是，神经网络有能力进行推理。但是如果你在一个不需要推理的任务上训练神经网络，它就不会去推理。这是一个众所周知的效应，神经网络会以最简单的方式精确地解决你摆在它面前的问题。

**Lex Fridman:** 这把我们带到了……你描述神经网络的一种绝妙方式，你将神经网络称为“寻找小电路”（search for small circuits），也许将通用智能称为“寻找小程”（search for small programs），我发现这个比喻非常引人入胜。你能详细说明一下这个区别吗？

**Ilya Sutskever:** 是的。所以我确切说的是，如果你能找到输出你所掌握数据的最短程序，那么你将能够用它做出最好的预测。这是一个可以用数学证明的理论陈述。现在你也可以用数学证明，找到生成某些数据的最短程序是不可计算的操作。没有有限的计算量可以做到这一点。

那么对于神经网络，神经网络是下一个在实践中真正有效的最佳选择。我们无法找到生成我们数据的最佳、最短程序。但是我们能够找到，你知道，一个小的……但现在这个陈述应该被修正……甚至是一个大的电路，以某种方式拟合我们的数据。

**Lex Fridman:** 我认为你说的“小电路”是指所需的最小电路。

**Ilya Sutskever:** 嗯，我明白了。现在我会改变的是……回到那时，我还没有完全内化过度参数化的结果，我们现在知道的关于过度参数化神经网络的事情。现在我会把它表述为一个“大型电路，其权重包含少量信息”，我认为这就是正在发生的事情。如果你把神经网络的训练过程想象成你缓慢地将熵从数据集传输到参数中，那么最终权重中的信息量并不会很大，这就解释了为什么它们泛化得那么好。所以就是这样。

**Lex Fridman:** 大型电路可能有助于正则化，有助于泛化？

**Ilya Sutskever:** 是的，其中一些……但是你认为能够……你认为尝试学习像程序这样的东西很重要吗？

**Ilya Sutskever:** 我的意思是，如果你能做到，那肯定……我认为答案有点像，是的，如果我们能做到，我们应该做我们能做的事情。这是我们推动深度学习的原因，根本原因，根源在于我们能够训练它们。

换句话说，训练优先。我们有我们的支柱，那就是训练支柱。现在我们试图围绕训练支柱扭曲我们的神经网络。我们必须保持可训练性。这是一个不变量，我们不能违反。所以，可训练性意味着从零开始，一无所知，你可以相当快地收敛到知道很多，甚至慢慢地。但这意味着，给定你可用的资源，你可以训练神经网络并让它达到有用的性能。

**Lex Fridman:** 是的，那是我们不能偏离的支柱。

**Ilya Sutskever:** 没错。而如果你说，“嘿，让我们找到最短的程序”，但我们做不到。所以它有多有用并不重要，我们做不到。所以我们想要……

**Lex Fridman:** 所以你认为……你提到神经网络擅长寻找小电路或大电路。那么你认为寻找小程序的问题仅仅是数据的问题吗？不是……

**Ilya Sutskever:** 不是……

**Lex Fridman:** ……大小或特征，而是数据的类型？比如给它程序？

**Ilya Sutskever:** 嗯，我认为问题在于，目前还没有很好的先例表明人们成功地很好地找到了程序。所以，你找到程序的方式将是……你基本上会训练一个深度神经网络来做这件事。

**Lex Fridman:** 对，这是正确的做法。

**Ilya Sutskever:** 但还没有很好的……例证表明它已经完成了。但原则上它应该是可能的。

**Lex Fridman:** 你能稍微详细说明一下吗？你……你在原则上的见解是什么？换句话说，你看不到为什么它不可能？

**Ilya Sutskever:** 嗯，这更像是一个……更像是一个声明，我认为……我认为赌深度学习会输是不明智的。而且如果这是一种人类似乎能够做到的认知功能，那么用不了多久就会出现某个深度神经网络也能做到。

**Lex Fridman:** 是的，我……我同意你的看法。我已经……在这一点上我已经不再赌神经网络会输了，因为它们持续给我们带来惊喜。那么长期记忆呢？神经网络能拥有长期记忆或类似知识库的东西吗？

**Ilya Sutskever:** 能够聚合……

**Lex Fridman:** ……在很长一段时间内聚合重要信息，然后这些信息可以作为有用的状态表示，你可以据此做出决策？所以……拥有一个长期的上下文，基于它来做决策？

**Ilya Sutskever:** 从某种意义上说，参数已经做到了这一点。参数是神经网络整个经验的聚合。所以它们可以算作长期知识。人们已经训练了各种神经网络来充当知识库，你知道，研究过……人们已经将语言模型作为知识库进行了研究。所以有工作……那里有工作。是的。

**Lex Fridman:** 但在某种意义上……你认为在每种意义上……你认为这都只是一个想出更好的机制来忘记无用东西、记住有用东西的问题吗？因为现在……我的意思是，还没有能够真正记住长期信息的机制。

**Ilya Sutskever:** 你具体指的是什么？我喜欢“精确地”这个词。

**Lex Fridman:** 我在想知识库所代表的那种信息压缩。比如创建一个……现在我为我以人类为中心思考知识是什么而道歉，因为神经网络发现的知识不一定是可解释的。但对我来说一个好的例子是知识库，能够随着时间推移建立起像维基百科所代表的那种知识。它是一个非常压缩的、结构化的知识库。显然不是实际的维基百科或语言，而是像语义网（Semantic Web）所代表的梦想。所以它是一个非常好的压缩知识库，或者类似的东西，在神经网络会拥有的那种不可解释的意义上。

**Ilya Sutskever:** 嗯，神经网络如果你看它们的权重可能是不可解释的，但它们的输出应该非常可解释。

**Lex Fridman:** 好吧。所以，是的。你如何让非常智能的神经网络，比如语言模型，变得可解释？

**Ilya Sutskever:** 嗯，你让它们生成一些文本。那么这些文本通常是可解释的。

**Lex Fridman:** 你觉得那是可解释性的极致吗？比如你能做得更好吗？比如你能……因为你不能……好吧。我想知道它知道什么，不知道什么。我希望神经网络能够举出它完全愚蠢的例子和它完全聪明的例子。而我现在知道的唯一方法是生成大量例子，并使用我的人类判断力。但如果一个新生儿有一些……自我意识，那会很好。

**Ilya Sutskever:** 是的，100%。我是自我意识的坚定信徒。我认为……我认为神经网络的自我意识将允许像你描述的那样的能力，比如让它们知道自己知道什么、不知道什么，让它们知道在哪里投入以最优化地提升技能。

关于你问的可解释性问题，实际上有两个答案。一个答案是，你知道，我们有神经网络，所以我们可以分析神经元，我们可以尝试理解不同神经元和不同层意味着什么。你实际上可以做到这一点，OpenAI 已经在这方面做了一些工作。

但还有另一个答案，我会说这是以人为中心的答案。就是你说，你知道，你看一个人，你读不懂……你知道，你怎么知道一个人在想什么？你问他们。你说，“嘿，你对这个怎么看？你对那个怎么看？” 你得到一些答案。你得到的答案是有粘性的（sticky），因为你已经有了一个心智模型，你已经对那个人有了一个……是的，心智模型，你已经对那个人有了一个理解，一个关于他/她如何思考、知道什么、如何看待世界的大概念。然后你问的每一件事都是在这个基础上增加的。而这种粘性似乎是……这是人类非常有趣的品质之一，信息是有粘性的。你似乎记得有用的东西，很好地聚合它，并忘记大部分无用的信息。

**Lex Fridman:** 那个过程……

**Ilya Sutskever:** 但这也非常类似于神经网络所做的过程，只是神经网络目前在这方面做得差得多。它似乎并没有根本的不同。

但让我们再稍微谈谈推理。你说“为什么不呢？为什么不能推理？” 对你来说，一个令人印象深刻的推理壮举或基准是什么？你会对其印象深刻的，如果你不知道我们能做什么？这是你已经想到的东西吗？

**Ilya Sutskever:** 嗯，我认为是写出真正好的代码。我认为是证明真正困难的定理。解决开放式问题，用跳出常规的解决方案。

**Lex Fridman:** 还有……定理类型的数学问题？

**Ilya Sutskever:** 是的，我认为那些也是一个非常自然的例子。你知道，如果你能证明一个未被证明的定理，那么很难争辩说你没有推理。顺便说一下，这又回到了关于确凿结果的观点。你知道，如果你有一个确凿的……如果你有……机器学习、深度学习作为一个领域是非常幸运的，因为我们有能力有时产生这些明确无误的结果。当它们发生时，辩论就改变了，对话就改变了。这是一个对话……我们有能力产生改变对话的结果。

**Lex Fridman:** 然后当然，就像你说的，人们有点认为那是理所当然的，然后说那其实不是一个难题。

**Ilya Sutskever:** 嗯，我的意思是，总有一天我们可能会耗尽难题。

**Lex Fridman:** 是的，那个……整个死亡问题有点……有点棘手，我们还没完全弄明白。也许我们会解决那个问题。

**Ilya Sutskever:** 我认为在你整个工作体系中，以及最近在 OpenAI 的工作中，最引人入胜的事情之一，改变对话的事情之一，是在语言模型的世界里。你能简要地尝试描述一下近期在语言和文本领域使用神经网络的历史吗？

**Ilya Sutskever:** 嗯，历史很长。我认为 Elman 网络是……是……是一个应用于语言的小型循环神经网络，早在 80 年代。所以历史真的……相当长，至少。

而开始改变神经网络和语言轨迹的事情，正是改变深度学习轨迹的事情，那就是数据和计算能力。所以突然之间，你从学习一点点的小型语言模型转向……对于语言模型尤其如此，有一个非常清晰的解释为什么它们需要很大才能做得好。因为它们试图预测下一个词。当你什么都不知道的时候，你会注意到非常非常粗略的表面模式，比如有时有字符，字符之间有空格，你会注意到这个模式。你会注意到有时有逗号，然后下一个字符是大写字母，你会注意到那个模式。最终你可能会开始注意到某些词经常出现。你可能会注意到拼写是一回事。你可能会注意到语法。当你对所有这些都非常擅长时，你开始注意到语义。你开始注意到事实。但要发生这种情况，语言模型需要更大。

**Lex Fridman:** 让我们在这停留一下，因为这是你和诺姆·乔姆斯基意见不同的地方。所以你认为我们实际上正在采取……渐进的步骤，一种……更大的网络、更大的计算能力将能够达到语义层面，能够理解语言，而不需要诺姆喜欢认为的那种……对语言结构的基本理解，比如把你的语言理论强加到学习机制上？所以你是说学习……你可以从原始数据中学习语言背后的机制？

**Ilya Sutskever:** 嗯，我认为……我认为这很有可能。但我也想说，我并不真正确切地知道乔姆斯基谈论……你说了些关于强加你的结构和语言……我不太确定他是什么意思。但从经验上看，似乎当你检查那些更大的语言模型时，它们表现出理解语义的迹象，而较小的语言模型则没有。

几年前我们做情感神经元（sentiment neuron）的工作时就看到了这一点。我们训练了一个小的……你知道，更小的 LSTM 来预测亚马逊评论中的下一个字符。我们注意到，当你把 LSTM 的大小从 500 个 LSTM 单元增加到 4000 个 LSTM 单元时，其中一个神经元开始代表评论文章的情感。现在，为什么呢？情感是一个相当语义化的属性，它不是一个句法属性。

**Lex Fridman:** 对于可能不知道的人，我不知道这是否是标准术语，但情感是指评论是正面的还是负面的。

**Ilya Sutskever:** 没错。比如这个人对某事满意还是不满意。所以在这里我们有非常明确的证据表明，一个小的神经网络不捕捉情感，而一个大的神经网络则捕捉情感。为什么呢？嗯，我们的理论是，在某个时候，你耗尽了可以建模的语法，你必须开始关注别的东西。随着规模的增大，你很快就耗尽了可以建模的语法，然后你真正开始关注语义，这就是想法。

**Lex Fridman:** 这就是想法。

**Ilya Sutskever:** 没错。所以我不想暗示我们的模型有完整的语义理解，因为那不是真的。但它们肯定显示出语义理解的迹象，部分的语义理解。但是较小的模型没有显示出那些迹象。

**Lex Fridman:** 你能退一步说一下，什么是 GPT-2？它是过去几年中改变对话的大型语言模型之一。

**Ilya Sutskever:** 是的。所以 GPT-2 是一个拥有 15 亿参数的 Transformer，它在大约 400 亿个文本 token 上进行了训练，这些 token 来自于从 Reddit 上获得超过 3 个点赞的文章链接到的网页。

**Lex Fridman:** Transformer 是什么？

**Ilya Sutskever:** Transformer 是近期神经网络架构中最重要的进展。

**Lex Fridman:** 也许还有注意力（Attention）机制？因为我认为那是有趣的想法，不一定是技术上讲，而是注意力的想法，相对于循环神经网络可能代表的东西。

**Ilya Sutskever:** 是的。所以问题是，Transformer 是多种思想同时结合的产物，注意力是其中之一。

**Lex Fridman:** 你认为注意力是关键吗？

**Ilya Sutskever:** 不。它是关键之一，但不是唯一关键。Transformer 之所以成功，是因为它是多种思想的同时结合。如果你移除其中任何一个思想，它的成功程度都会大打折扣。所以 Transformer 使用了大量的注意力机制，但注意力机制已经存在了好几年，所以那不可能是主要的创新。Transformer 的设计方式使得它在 GPU 上运行得非常快，这带来了巨大的差异。这是一点。第二点，Transformer 不是循环的，这一点也非常重要。因为它更浅（shallow），因此更容易优化。换句话说，它使用了注意力机制，它非常适合 GPU，并且它不是循环的，因此更不深（less deep）且更容易优化。这些因素的结合使其成功。所以现在它极大地利用了你的 GPU，它让你用同样的计算量获得更好的结果，这就是它成功的原因。

**Lex Fridman:** 你对 Transformer 的效果如此之好感到惊讶吗？以及 GPT-2 的效果？你在语言领域工作过，在 Transformer 出现之前你有很多很棒的想法。所以你看到了之前和之后的所有革命。你感到惊讶吗？

**Ilya Sutskever:** 是的，有点。有点惊讶。是的。我的意思是，很难……很难记清了，因为你适应得非常快。但它肯定令人惊讶。它肯定……事实上，你知道吗？我会撤回我的说法。它……它相当惊人。看到它生成那种文本，简直太棒了。而且，你知道，你要记住，在那时我们已经看到了 GANs 的所有进展，在改进……你知道，GANs 生成的样本简直太棒了。你有那些逼真的人脸。但文本并没有真正移动那么多。突然之间，我们从……你知道，2015 年的 GANs 是什么样，一步就跳到了最好、最惊人的 GANs。

**Lex Fridman:** 对。

**Ilya Sutskever:** 这真的令人震惊。即使理论预测，“是的，你训练一个大型语言模型，当然你应该得到这个。”但亲眼看到它，是另一回事。然而我们适应得非常快。现在……

**Lex Fridman:** ……有一些认知科学家写文章说 GPT-2 模型并没有真正理解语言。所以我们很快就适应了它们能够如此好地建模语言这一惊人事实。那么你认为让我们印象深刻的标准是什么？它……我不知道。你认为这个标准会不断提高吗？

**Ilya Sutskever:** 当然。我认为当你开始看到真正显著的经济影响时，那时……我认为这在某种意义上是下一个障碍。因为现在，如果你思考 AI 的工作，真的令人困惑，真的很难理解所有这些进展意味着什么。有点像，“好吧，你取得了一个进展，现在你可以做更多的事情了。你又得到了另一个改进，你又得到了另一个很酷的演示。” 在某个时候，我认为 AI 领域之外的人们再也无法区分这种进步了。

**Lex Fridman:** 我们私下聊到过俄语翻译成英语，以及有很多杰出的俄语工作成果世界其他地方并不知道。这对中文也是如此，对很多……对很多科学家和一般的艺术工作也是如此。你认为翻译是我们将会看到……比如经济上巨大影响的地方吗？

**Ilya Sutskever:** 我……我不知道。我认为……我认为有大量的……我的意思是，首先，我想指出，今天的翻译已经非常巨大了。我认为数十亿人主要通过翻译与互联网的大部分内容互动。所以翻译已经很巨大了，而且它也具有巨大的、巨大的积极作用。

我认为自动驾驶将产生巨大的影响。而且你知道，它……确切何时发生是未知的。但同样，我不会赌深度学习会输。

**Lex Fridman:** 所以……那是广义的深度学习，但你……用于自动驾驶的深度学习？

**Ilya Sutskever:** 是的。

**Lex Fridman:** 用于自动驾驶的深度学习。但我刚才说的是语言模型。让我们……只是为了……稍微偏离一下，只是为了确认，你没有看到驾驶和语言之间的联系？

**Ilya Sutskever:** 不，不。

**Lex Fridman:** 好吧。好吧。它们都使用神经网络。

**Ilya Sutskever:** 这会是一种诗意的联系。我认为可能有一些……就像你说的，可能会有某种统一，走向一种……一种多任务 Transformer，可以同时处理语言和视觉任务。那将是一个有趣的统一。

**Lex Fridman:** 好吧。让我看看关于 GPT-2 我还能问些什么。嗯……它很简单。没什么可问的。就是你拿一个 Transformer，把它做得更大，给它更多数据，突然它就做了所有那些令人惊奇的事情。

**Ilya Sutskever:** 是的，其中一个美妙之处在于，GPG……Transformer 从根本上讲易于解释、易于训练。

**Lex Fridman:** 你认为在语言领域，“更大”会继续显示出更好的结果吗？

**Ilya Sutskever:** 可能。

**Lex Fridman:** 有点像……对于 GPT-2，你认为下一步是什么？

**Ilya Sutskever:** 我的意思是，我认为，肯定的是，看看更大版本能做什么是一个方向。而且，我的意思是，有很多……有很多问题。有一个我很好奇的问题，那就是：现在 GPT-2……我们喂给它所有来自互联网的数据，这意味着它需要记住互联网上关于所有事情的所有那些随机事实。如果模型能以某种方式利用它自己的智能来决定它想学习哪些数据，接受哪些数据，拒绝哪些数据，那会很好。就像人类一样。人类不会不加选择地学习所有数据。我们对我们学习什么超级挑剔。我认为这种主动学习（Active Learning），我认为拥有它会非常好。

**Lex Fridman:** 是的，听着，我喜欢主动学习。

**Lex Fridman:** 让我问一下，数据的选择……你能稍微详细说明一下吗？你认为数据的选择是……比如我有一种感觉，优化你如何选择数据的方式，也就是主动学习过程，将是很多突破发生的地方，即使在不久的将来。因为在那里还没有很多公开的突破。我觉得可能有一些公司自己保留的私下突破，因为如果你想解决自动驾驶，如果你想解决某个特定任务，这个基本问题必须解决。但你对这个领域总体怎么看？

**Ilya Sutskever:** 是的。所以我认为对于像主动学习这样的东西，或者实际上对于任何像主动学习这样的能力，它真正需要的是一个问题。它需要一个需要它的问题。如果你没有一个任务，就很难对能力进行研究。因为那样会发生的是，你会想出一个人工任务，得到好的结果，但并不能真正说服任何人。

**Lex Fridman:** 对。就像我们现在已经过了在 MNIST 上得到一个结果……在 MNIST 上提出一些巧妙的公式就能说服人们的阶段了。

**Ilya Sutskever:** 没错。事实上，你可以很容易地在 MNIST 上想出一个简单的主动学习方案，并获得 10 倍的加速，但那又怎样呢？我认为对于主动学习，需要……主动学习会自然而然地出现，随着需要它的问题的出现而出现。这就是我的看法。

**Lex Fridman:** 还有一件有趣的事情是 OpenAI 随着 GPT-2 提出的，那就是……

**Lex Fridman:** 当你创建一个强大的人工智能系统时，它是不清楚的……一旦你发布 GPT-2，它会产生什么样的有害影响是不清楚的。因为如果你有一个可以生成相当逼真文本的模型，你可以开始想象，你知道，在……它会被机器人使用，以某种我们甚至无法想象的方式。所以，对于它可能做的事情存在这种紧张感。所以你做了一件非常……有点勇敢，我认为是深刻的事情，你开启了关于这个问题的对话。比如我们如何向公众发布强大的人工智能模型？如果我们发布的话？我们如何私下地，甚至与竞争对手讨论我们如何管理这些系统的使用等等？所以从这整个经历中，你发布了一份关于它的报告，但总的来说，仅仅通过思考这个问题，你有没有收集到任何关于如何发布这类模型的见解？

**Ilya Sutskever:** 我的意思是，我认为我对这个问题的看法是，AI 领域一直处于童年期，现在它正在走出那个状态，进入成熟期。这意味着 AI 非常成功，而且影响巨大。它的影响不仅巨大，而且还在增长。因此，出于这个原因，在发布我们的系统之前开始考虑其影响似乎是明智的，宁可稍微早一点，也不要稍微晚一点。

对于 GPT-2 的情况，就像我之前提到的，结果确实令人震惊。似乎有理由相信——并非确定，但似乎有理由相信——像 GPT-2 这样的东西很容易被用来降低虚假信息的成本。所以就有一个问题，最好的发布方式是什么？分阶段发布（Staged release）似乎是合乎逻辑的。发布了一个小模型，然后有时间观察……许多人以各种很酷的方式使用了这些模型。有很多非常酷的应用。我们没有听说任何负面应用。所以最终它被发布了。但其他人也复制了类似的模型。

**Lex Fridman:** 不过，“我们知道的”这是一个有趣的问题。所以在你看来，分阶段发布是……至少是回答我们如何……我们创建了这样的系统后该怎么做这个问题的部分答案？

**Ilya Sutskever:** 它是答案的一部分，是的。

**Lex Fridman:** 还有其他见解吗？比如说，你根本不想发布模型，因为它对你的业务无论如何都有用。

**Ilya Sutskever:** 嗯，有很多人已经不发布模型了。

**Lex Fridman:** 对，当然。但是当你拥有一个非常强大的模型时，是否存在某种道德伦理责任来……比如沟通？就像你说的，当你拥有 GPT-2 时，不清楚它在多大程度上可能被用于制造虚假信息。这是一个开放的问题。而得到答案可能需要你与其他非常聪明的人交谈，那些在你特定群体之外的人。你……请告诉我，世界各地的人们在这些案例上进行合作存在某种乐观的途径吗？还是从一个公司与另一个公司交谈仍然非常困难？

**Ilya Sutskever:** 这绝对是可能的。绝对有可能与其他地方的同事讨论这类模型，并征求他们对该怎么做的看法。

**Lex Fridman:** 但这有多难呢？我的意思是，你看到这种情况发生吗？

**Ilya Sutskever:** 我认为那是一个需要逐渐在公司之间建立信任的地方。因为最终所有的 AI 开发者都在构建技术，而这些技术注定会变得越来越强大。所以……思考它的方式是，最终我们是在一起的。

**Lex Fridman:** 是的，这……我倾向于相信我们本性中善良的一面，但我确实希望……当你……当你在特定领域构建了一个非常强大的 AI 系统时，你也会思考……潜在的负面后果。

**Ilya Sutskever:** ……这是一个有趣且可怕的可能性，即 AI 开发将是一场竞赛，这会促使人们封闭开发，不与他人分享想法。

**Lex Fridman:** 我不喜欢这样。我做了十年的纯粹学者，我真的很喜欢分享想法，这很有趣，很令人兴奋。

## **VI. 通往通用人工智能（AGI）之路**

**Lex Fridman:** 你认为需要什么……让我们稍微谈谈 AGI。你认为构建一个达到人类水平智能的系统需要什么？我们谈到了推理，我们谈到了长期记忆，但总的来说，你认为需要什么？

**Ilya Sutskever:** 嗯，我不能确定。但我认为是深度学习加上也许另一个小想法。

**Lex Fridman:** 你认为自博弈（Self-play）会参与其中吗？比如你谈到过自博弈的强大机制，系统通过在竞争环境中与技能相当的其他实体对抗来学习，并以此方式逐步改进。你认为自博弈会是构建 AGI 系统的一个组成部分吗？

**Ilya Sutskever:** 是的。所以我会说，要构建 AGI，我认为将是深度学习加上一些想法。我认为自博弈将是那些想法之一。我认为那是一个非常……自博弈具有这种惊人的特性，它能以真正新颖的方式给我们带来惊喜。例如……我的意思是，几乎每一个自博弈系统，无论是我们的 Dota 机器人，我不知道 OpenAI 是否发布过关于多智能体（multi-agent）的消息，其中有两个小智能体在玩捉迷藏，当然还有 AlphaZero，它们都有令人惊讶的行为。它们都产生了我们没预料到的行为。它们是对问题的创造性解决方案。这似乎是 AGI 的一个重要组成部分，而我们的系统目前并没有常规地展示出来。所以这就是为什么我喜欢这个领域，我喜欢这个方向，因为它有能力给我们带来惊喜。

**Lex Fridman:** 给我们带来惊喜，而一个 AGI 系统会从根本上给我们带来惊喜。

**Ilya Sutskever:** 是的。但要精确地说，不仅仅是……不仅仅是随机的惊喜，而是找到一个对问题既有用又令人惊讶的解决方案。

**Lex Fridman:** 对。现在很多自博弈机制被用在游戏环境，或者至少是模拟环境中。你认为……你认为在通往 AGI 的道路上，有多少将通过模拟完成？你对模拟有多大的信心和希望？相对于必须拥有一个在现实世界中运行的系统——无论是数字现实世界的数据，还是像机器人那样的实际物理世界？

**Ilya Sutskever:** 我不认为这是“非此即彼”。我认为模拟是一个工具，它有帮助。它有特定的优点和缺点，我们应该使用它。

**Lex Fridman:** 是的，但我明白……那……那是……那是真的。但是对自博弈的一个批评，对强化学习的一个批评是，它目前的……它目前的力量，它目前的结果，虽然惊人，但都是在模拟环境或非常受限的物理环境中展示的。你认为有可能逃离它们吗？逃离模拟环境，能够在非模拟环境中学习？或者你认为也有可能……只是以照片般逼真和物理上逼真的方式模拟现实世界，以至于我们可以在模拟中通过自博弈解决现实问题？

**Ilya Sutskever:** 所以我认为从模拟到现实世界的迁移（Transfer）绝对是可能的，并且已经被许多不同的团体多次展示过。它在视觉领域尤其成功。

OpenAI 在夏天也展示了一个机器人手，它完全在模拟中以某种方式训练，允许“零样本迁移”（sim-to-real transfer）发生。

**Lex Fridman:** 这是……用于魔方的那个？

**Ilya Sutskever:** 没错。

**Lex Fridman:** 我不知道那是在模拟中训练的。

**Ilya Sutskever:** 它完全在模拟中训练。真的。

**Lex Fridman:** 所以它不是在物理……手不是被训练……

**Ilya Sutskever:** 不。100% 的训练是在模拟中完成的。在模拟中学到的策略被训练得非常具有适应性。适应性强到当你迁移它时，它可以非常快地适应物理……物理世界。

**Lex Fridman:** 所以用长颈鹿或不管那是什么东西进行的扰动……那些不是……那些是模拟的一部分吗？

**Ilya Sutskever:** 嗯，模拟……模拟通常被训练成对许多不同的事物具有鲁棒性，但不是我们在视频中看到的那种扰动。所以它从未戴着手套训练过，它从未用填充长颈鹿训练过。

**Lex Fridman:** 所以理论上这些是新颖的扰动？

**Ilya Sutskever:** 正确。

**Lex Fridman:** 不是理论上，是实践中那些是新颖的扰动。

**Ilya Sutskever:** 嗯，好吧。那是一个干净的、小规模但干净的例子，展示了从模拟世界到物理世界的迁移。

**Ilya Sutskever:** 是的。我还会说，我预计深度学习的迁移能力总体上会增强。迁移能力越好，模拟就越有用。因为那样你就可以……你可以在模拟中体验某事，然后学到一个“故事的寓意”，然后你可以把它带到现实世界中去。

**Lex Fridman:** 对，就像人类一直做的那样，当他们玩电脑游戏时。

**Lex Fridman:** 让我问一个……关于具身化（embodied）的问题，继续谈 AGI 一会儿。你认为 AGI 系统需要拥有一个身体吗？我们需要拥有那些人类的元素，比如自我意识、意识、比如……对死亡的恐惧或在物理空间中的自我保护，这些都伴随着拥有身体而来？

**Ilya Sutskever:** 我认为拥有身体会有用。我不认为它是必需的。但我认为拥有身体肯定非常有用。因为你可以学习全新的……你可以学习没有身体就无法学习的东西。但同时，我认为如果你没有身体，你可以弥补它，并且仍然成功。

**Lex Fridman:** 你这么认为？

**Ilya Sutskever:** 是的。嗯，有证据支持这一点。例如，有很多人天生聋哑和失明，他们能够弥补感官的缺失。我想到的是海伦·凯勒。所以即使你无法与世界进行物理互动，即使你无法……我的意思是，我实际上是在想……也许让我问……

**Lex Fridman:** ……更具体一点。我不确定这是否与拥有身体有关，但关于意识（Consciousness）的概念，以及一个更受限的版本，自我意识（Self-awareness）。你认为一个 AGI 系统应该拥有意识吗？就是我们无法定义的那种……不管你认为意识是什么的那种东西？

**Ilya Sutskever:** 是的，考虑到定义它的难度，这是一个很难回答的问题。

**Lex Fridman:** 你认为思考这个问题有用吗？

**Ilya Sutskever:** 我的意思是，这绝对有趣。它引人入胜。我认为我们的系统拥有意识绝对是可能的。

**Lex Fridman:** 你认为这是一种涌现（emergent）的东西吗？就是来自于……你认为意识可以从存储在神经网络内部的表示中涌现出来吗？就像……当你变得越来越……能够表示越来越多的世界时，它自然就涌现出来了？

**Ilya Sutskever:** 嗯，我会提出以下论点，那就是人类是有意识的。如果你相信人工神经网络与大脑足够相似，那么至少应该存在……人工神经……也应该是有意识的。

**Lex Fridman:** 你非常依赖那个存在性证明。好吧。

**Ilya Sutskever:** 但这只是……那是我能给出的最好的答案。

**Lex Fridman:** 不，我……我知道，我知道，我知道。这仍然是一个悬而未决的问题，大脑中是否没有一些我们没有……我的意思不是非物质的魔法，而是……大脑可能比我们认为的要复杂得多、有趣得多。

**Ilya Sutskever:** 如果是这样的话，那它应该会显现出来。在某个时候……在某个时候我们会发现我们无法继续取得进展。但我认为……我认为这不太可能。

**Lex Fridman:** 所以我们谈论了意识，但让我谈谈另一个定义不清的概念：智能（Intelligence）。同样，我们谈到了推理，我们谈到了记忆。你认为对你来说，一个好的智能测试是什么？你对艾伦·图灵用模仿游戏（Imitation Game）通过自然语言制定的测试印象深刻吗？在你心目中，有没有什么东西，如果一个系统能够做到，会让你深深地震撼？

**Ilya Sutskever:** 我的意思是，很多事情。有某些……有某些当今能力的前沿。是的。存在于那个前沿之外的事物。任何这样的事物都会让我印象深刻。例如，我会对一个深度学习系统印象深刻，它解决一个非常普通的……你知道，普通的任务，比如机器翻译或计算机视觉任务，或者别的什么，并且在任何情况下都不会犯人类不会犯的错误。我认为这是尚未被证明的事情，我会觉得它非常令人印象深刻。

**Lex Fridman:** 是的。所以现在它们会犯错误，并且不同……它们可能比人类更准确，但它们仍然……它们犯的是不同类型的错误。

**Ilya Sutskever:** 所以我的……我的猜测是，很多人对深度学习的怀疑，是当他们看到它们的错误时，他们会说，“嗯，那些错误毫无意义。如果你理解了这个概念，你就不会犯那个错误。” 我认为改变这一点会……会……那会激励我。那会是，“是的，这是……这是……这是进步。”

**Lex Fridman:** 是的，这……这是一个非常好的表达方式。但我也只是不喜欢那种人类本能地批评一个模型不智能。这与我们批评任何群体为“他者”是同样的本能。因为很有可能 GPT-2 在很多方面比人类聪明得多。

**Ilya Sutskever:** 这绝对是真的。它拥有更广泛的知识。

**Lex Fridman:** 是的，知识的广度。甚至……甚至在某些主题上可能有深度。很难判断深度意味着什么。

**Ilya Sutskever:** 但肯定有一种感觉，人类不会犯这些模型所犯的错误。

**Lex Fridman:** 是的，同样的情况也适用于自动驾驶汽车。同样的情况可能将继续适用于许多人工智能系统。我们发现这是……令人烦恼的……这是 21 世纪分析 AI 进展的过程：寻找一个系统在人类不会失败的地方以重大方式失败的案例，然后许多人写关于它的文章，然后作为……公众普遍被说服该系统不智能，我们通过认为它因为这一个轶事案例而不智能来安抚自己。这似乎会继续发生。

**Ilya Sutskever:** 是的。我的意思是，这也有道理。虽然人们……我也确信很多人对现有的系统也印象极其深刻。但我认为这与我们之前讨论的观点有关，即判断 AI 的进展很令人困惑。

**Lex Fridman:** 是的。而且你知道，你有一个新的机器人在演示什么，你应该有多印象深刻？我认为人们会开始印象深刻，一旦 AI 开始真正推动 GDP 的指针。

**Lex Fridman:** 你是可能创造出 AGI 系统的人之一，不是你个人，而是你和 OpenAI。如果……如果你确实创造了一个 AGI 系统，并且你有机会和它——他、她——共度一个晚上，你会谈论什么？你认为第一次会是怎样？第一次？

**Ilya Sutskever:** 嗯，第一次我只会……我只会问各种各样的问题，试图让它……让它犯错误。我会惊叹于它不犯错误，然后就一直……一直问下去。

**Lex Fridman:** 你认为会是什么样的问题？会是事实性的，还是个人的、情感的、心理的？你认为呢？

**Ilya Sutskever:** 所有这些。

**Lex Fridman:** 你会寻求建议吗？

**Ilya Sutskever:** 当然。我的意思是，为什么……为什么我要限制自己与这样的系统交谈呢？

**Lex Fridman:** 现在，让我强调一下这个事实，你确实是可能在场见证这一切发生的人之一。所以让我问一个……关于……一个深刻的问题。我刚刚和一位斯大林历史学家谈过。我一直在和很多研究权力的人交谈。亚伯拉罕·林肯说过：“几乎所有人都能承受逆境，但如果你想考验一个人的品格，就赋予他权力。” 我想说，21 世纪的权力，也许是 22 世纪，但希望是 21 世纪，将是 AGI 系统的创造，以及那些直接拥有和控制 AGI 系统的人。所以你认为，在与 AGI 系统进行了那个晚上的讨论之后，你认为你会做什么？

**Ilya Sutskever:** 嗯，我想象的理想世界是人类就像……一个公司的董事会成员，而 AGI 是 CEO。所以会是……我会喜欢的图景是……我想象的是，你有某种不同的实体，不同的国家或城市，住在那里的人们投票决定代表他们的 AGI 应该做什么。然后代表他们的 AGI 去执行。我认为像那样的图景我非常喜欢。你可以有多个……你会有一个城市的 AGI，一个国家的 AGI，它们会试图……实际上是将民主进程提升到下一个层次。

**Lex Fridman:** 而董事会总是可以解雇 CEO。基本上按下重置按钮，然后说，“在这里重新随机化参数。”

**Ilya Sutskever:** 嗯，让我……那实际上……好吧，那是一个美好的愿景。我认为只要有可能按下重置按钮就行。你认为……永远有可能按下重置按钮吗？

**Ilya Sutskever:** 所以我认为这绝对……绝对有可能构建……所以你谈论……所以你问的问题我真正理解的是，我们人类，或者……人类，人们是否能控制他们构建的 AI 系统？

**Lex Fridman:** 是的。

**Ilya Sutskever:** 我的答案是，绝对有可能构建出**愿意**被其人类控制的 AI 系统。

**Lex Fridman:** 哇。那是它们……的一部分。

**Ilya Sutskever:** 所以不是说它们无法不被控制，而是……那是……那是它们存在的……它们存在的目标之一就是被控制。就像人类父母……通常想要帮助他们的孩子，他们希望他们的孩子成功。这对他们来说不是负担，他们很兴奋能帮助孩子，喂养他们，给他们穿衣，照顾他们。我相信，以最高的信念，同样的事情对于 AGI 也是可能的。有可能将 AGI 编程……设计成这样一种方式，它将拥有类似的深层驱动力，它会乐于去实现，而这个驱动力将是帮助人类繁荣昌盛。

**Lex Fridman:** 但让我退回到你创造 AGI 系统的那个时刻。我认为这是一个非常关键的时刻。在那个时刻和……拥有 AGI 作为领导者的民主董事会成员之间，必须有一个权力的放弃。乔治·华盛顿，尽管他做了所有坏事，但他做的一件大事是他放弃了权力。他首先不想当总统，即使当了总统，他也没有像大多数独裁者那样无限期地任职下去。你认为自己能够放弃对 AGI 系统的控制权吗？考虑到你可能对世界拥有的巨大权力？首先是经济上的，赚很多钱，对吧？然后是通过拥有 AGI 系统来控制？

**Ilya Sutskever:** 我觉得这样做微不足道。我觉得放弃这种……这种……我的意思是，你知道，你描述的那种场景对我来说听起来很可怕。那是我绝对不想处于的位置。

**Lex Fridman:** 你认为你代表了 AI 社区中的多数人还是少数人？

**Ilya Sutskever:** 嗯，我的意思是……

**Lex Fridman:** ……一个悬而未决的问题。一个重要的问题。大多数人是好人吗？这是另一种问法。

**Ilya Sutskever:** 所以我不知道大多数人是否是好人。但是我……我认为当事情真正重要的时候，人们可以比我们想象的更好。

**Lex Fridman:** 说得真美。是的。有没有……你能想到的具体的机制来使 AGI 的价值观与人类价值观对齐（Aligning）？你是否思考过这些在我们开发 AI 系统时持续对齐的问题？

**Ilya Sutskever:** 是的，当然。在某种意义上，你问的这类问题是……如果你必须把那个问题转换成今天的术语……

**Lex Fridman:** 是的。

**Ilya Sutskever:** ……这将是一个关于如何让一个 RL 智能体（agent）优化一个本身也是学习来的价值函数（value function）的问题。如果你看看人类，人类就是那样的。因为人类的奖励函数、价值函数不是外部的，它是内部的。

**Lex Fridman:** 没错。

**Ilya Sutskever:** 有明确的想法如何训练一个价值函数，基本上是一个目标……你知道，一个尽可能客观的感知系统，它将被单独训练来识别、内化人类在不同情况下的判断。然后那个组件将被整合为某个更强大的 RL 系统的基础价值函数。你可以想象这样一个过程。我不是说这就是那个过程，我是说这是一个你可以做的事情的例子。

## **VII. 哲学层面的反思**

**Lex Fridman:** 关于那个……人类存在的目标函数的话题。你认为隐含在人类存在中的目标函数是什么？生命的意义（Meaning of life）是什么？

**Ilya Sutskever:** 哦。我认为这个问题……在某种程度上是错误的。我认为这个问题暗示存在一个客观的答案，一个外部的答案。你知道，“你生命的意义是 X。” 对吧？我认为正在发生的是，我们存在，这很了不起。我们应该努力充分利用它，努力最大化我们自己短暂存在期间的价值和享受。

**Lex Fridman:** 有趣的是，因为行动确实需要一个目标函数。它肯定以某种形式存在，但很难明确表达出来。

**Ilya Sutskever:** 也许不可能明确表达出来，我猜这就是你的意思。而这是一个 RL 环境的有趣事实。

**Ilya Sutskever:** 嗯，但我提出的观点略有不同。那就是人类想要东西，他们的“想要”创造了驱动力，导致他们……你知道，我们的“想要”就是我们的目标函数，我们个体的目标函数。我们以后可以决定我们想要改变，我们以前想要的不再好了，我们想要别的东西。

**Lex Fridman:** 是的，但它们如此动态。一定有一些潜在的……比如弗洛伊德……有性的东西。有人认为这是对……对死亡的恐惧。还有对知识的渴望，你知道，所有这些东西。繁衍后代，比如所有的进化论观点。似乎可能存在某种基本的目标函数，其他一切都从中涌现出来。

**Ilya Sutskever:** 但这似乎……因为这非常重要。

**Ilya Sutskever:** 我认为……我认为可能有一个进化的目标函数，那就是生存和繁衍，并确保你的孩子成功。这是我的猜测。但这并没有回答“生命的意义是什么”这个问题。我认为你可以看到人类是如何成为这个宏大过程，这个古老过程的一部分。我们……我们存在于一个渺小的星球上。就是这样。所以，鉴于我们存在，努力充分利用它，并尽可能地享受更多、遭受更少。

**Lex Fridman:** 让我问两个关于生活的傻问题。一，你是否有遗憾的时刻？如果回到过去你会做得不同的时刻？二，是否有让你特别自豪、让你真正快乐的时刻？

**Ilya Sutskever:** 所以我可以回答……我可以回答这两个问题。当然，有大量的选择和决定，我做出的……事后看来，我不会那样做。我确实会感到一些遗憾。但是你知道，我试图从当时的知识中寻求慰藉，我当时已经尽力了。

就我引以为豪的事情而言，我非常幸运能够……拥有……做过让我引以为豪的事情。它们让我快乐了一段时间。但我不认为那是幸福的源泉。

**Lex Fridman:** 所以你的学术成就，你所有的论文，你是世界上被引用最多的人之一，我提到的所有在计算机视觉和语言等方面的突破……对你来说，幸福和自豪的源泉是什么？

**Ilya Sutskever:** 我的意思是，所有那些事情肯定是自豪的源泉。我非常……感激能够做所有那些事情，而且做它们非常有趣。但是幸福来自于……

**Lex Fridman:** 但你知道，你可以……幸福……嗯，我目前的观点是，幸福在很大程度上来自于我们看待事物的方式。你知道，你可以吃一顿简单的饭，结果却很开心。或者你可以和某人交谈，结果也很开心。或者反过来，你可以吃一顿饭，然后失望于这顿饭不是一顿更好的饭。所以我认为很多幸福来自于此。但我不确定。我不想太自信。

**Lex Fridman:** 在不确定性面前保持谦逊似乎也是这整个幸福事情的一部分。

**Ilya Sutskever:** 嗯……我认为没有比……生命的意义和关于幸福的讨论更好的结束方式了。所以，Ilya，非常感谢你。你给了我一些不可思议的想法。你给了世界许多不可思议的想法。我真的很感激。谢谢你今天的谈话。

**Ilya Sutskever:** 是的，谢谢你的到访。我真的很享受。

---

---

# 要点回顾


**I. 深度学习革命的开端与核心直觉**

-   AlexNet论文（由Ilya Sutskever, Alex Krizhevsky, Geoffrey Hinton合著）是深度学习革命的关键催化剂。
-   Ilya的关键认识（约2010-2011年）：大型、深层神经网络可以通过反向传播进行端到端训练（受James Martens的Hessian-free优化器工作的启发）。
-   核心直觉：如果能训练一个大型神经网络，它就能表示非常复杂的函数，类似于人脑在短时间内（如100毫秒，约10层神经元激活）识别物体的能力。
-   成功的关键要素设想：大型神经网络 + 大量监督数据 = 成功。
-   对过参数化的看法：当时理论（尽管不完整）认为数据多于参数可避免过拟合，且数据增强等方法可缓解此问题，因此过参数化并非主要障碍。
-   当时的主要疑虑：计算能力是否足够训练足够大的网络？Alex Krizhevsky的高效CUDA内核解决了这个问题。
-   触发点：高效计算（GPU内核）+ 大规模数据集（ImageNet）+ 坚定的信念 = AlexNet的诞生。

**II. 深度学习的基本概念与机制**

-   大脑的启发作用：是深度学习研究者直觉和灵感的重要来源（例如，从McCulloch-Pitts神经元到卷积网络）。
-   人工神经网络（ANN）与大脑的差异思考：
    -   脉冲（Spikes）：Ilya认为其重要性优先级不高，脉冲神经网络常需模拟非脉冲网络才能工作。
    -   学习规则：提及脉冲时间依赖可塑性（STDP）作为大脑中可能存在的、值得研究的不同学习机制。
-   循环神经网络（RNNs）：
    -   定义：维护一个高维隐藏状态，并根据接收到的观测值更新该状态。
    -   能力：Ilya认为RNN（及其后继者如Transformer）非常强大，能够实现期望的功能。
    -   未来：尽管目前被Transformer超越，但某种形式的循环（Recurrence）可能会回归。
    -   与知识库的联系：RNN的隐藏状态和连接权重可以类比于存储知识和进行短期处理。
-   代价函数（Cost Functions）：
    -   重要性：是深度学习中的一个核心思想，用于衡量系统性能。
    -   局限性思考：是否存在无代价函数或动态代价函数的学习方式？GAN（生成对抗网络）是一个例子，其行为由博弈均衡而非单一优化目标决定。
    -   Ilya的态度：非常欣赏代价函数，认为其极其有用，不应轻易摒弃。
-   反向传播（Backpropagation）：
    -   评价：Ilya是其坚定支持者，认为它解决了在约束条件下寻找神经回路这一根本性问题。
    -   与生物学习的关系：承认大脑中似乎没有反向传播（Hinton的观点），但如果发现了大脑的学习机制，也应研究和借鉴。
    -   实用性：目前极其有用，不太可能被完全不同的方法取代，可训练性是关键支柱。
-   深度学习成功的关键因素（再述）：
    -   现有思想的整合：基本思想早已存在。
    -   大规模监督数据：例如ImageNet。
    -   强大的计算能力：特别是GPU的普及。
    -   信念（Conviction）：坚信将已有思想与数据、计算结合能够成功。
    -   基准（Benchmarks）：困难的基准测试提供了无可辩驳的证据，推动了领域发展，减少了无休止的争论。

**III. 不同学习领域的比较与统一**

-   机器学习的统一性：不同模态（视觉、语言、强化学习）之间存在大量的思想和原则重叠。一个领域的优化改进常能惠及其他领域。
-   视觉（Vision）与自然语言处理（NLP）：
    -   相似性：如今两者非常相似，都受益于深度学习的统一方法。
    -   差异：目前使用不同架构（CNN vs Transformer），但未来可能统一到单一架构。
    -   哪个更难？Ilya认为语言理解可能更难（取决于定义），但也指出两者高度关联（如阅读文字涉及视觉）。可能深度理解任一领域都需要相似的系统，从而“免费”获得另一领域的能力。
-   强化学习（Reinforcement Learning, RL）：
    -   独特性：需要采取行动、处理探索问题、方差更大、环境非稳态（智能体行为改变其观测）。
    -   与其它领域的统一性：尽管存在差异，但与视觉、NLP共享大量基础（如神经网络、梯度、优化器），并与之自然接口。预期未来RL与监督学习会进一步融合。

**IV. 深度学习的力量、奥秘与挑战**

-   深度学习最令人惊讶之处：它“竟然真的有效”。简单的组件（神经元、反向传播）通过规模化和数据驱动，能够学习复杂的类脑功能，并且持续超出预期。
-   对深度学习的低估：Ilya认为我们仍在“大规模地低估”深度学习的能力，它的潜力不断展现。
-   深度双重下降（Deep Double Descent）：
    -   现象：模型复杂度（如大小）增加时，测试误差先下降，在某个点（接近零训练误差的插值阈值）上升，然后再次下降。
    -   条件：在不使用早停（Early Stopping）的情况下更明显。
    -   解释：在插值阈值附近，模型对训练数据的微小随机扰动极其敏感。而在参数远多于数据或远少于数据时，找到的解（如SGD找到的低范数解）对这种随机性不敏感。
    -   意义：挑战了传统统计学习理论，揭示了过参数化模型的良好泛化能力。
-   神经网络的推理能力：
    -   可能性：Ilya认为神经网络“为什么不能”推理？AlphaZero（仅神经网络部分）在围棋（需要推理）上超越多数人类是证据。人类能推理，神经网络也应能。
    -   现状：现有网络能够推理，但前提是训练任务明确要求推理；否则它们会选择最简单的路径解决问题。
    -   衡量标准：能解决需要创造性、开箱即用方案的问题（如证明新定理、编写高质量代码）。
-   长期记忆与知识库：
    -   现有机制：网络参数本身就是一种长期记忆，聚合了训练经验。语言模型已被探索作为知识库。
    -   未来方向：需要更好的机制让模型自主选择学习内容（主动学习 Active Learning），并具备自我意识（知道自己知道什么、不知道什么）。
    -   可解释性：可以通过分析神经元活动，或通过人机对话（提问）来理解模型。

**V. 语言模型、GPT-2与伦理考量**

-   大型语言模型的崛起：数据和算力的增长使得模型能从表面模式（字符、空格）学习到句法，再到语义和事实。
-   语义理解的证据：在训练更大模型（如从500单元到4000单元的LSTM）时，出现了能表征情感（一种语义概念）的神经元。模型越大，越能捕捉语义信息（尽管目前只是部分理解）。
-   GPT-2：
    -   技术细节：基于Transformer架构，15亿参数，训练数据约400亿token（来自Reddit链接的高质量网页）。
    -   Transformer架构：结合了多种思想（注意力机制、GPU优化设计、非循环结构带来的易优化性），是近年重要的架构进展。
    -   效果：生成文本质量惊人，实现了语言生成领域的巨大飞跃。
-   语言模型的未来：更大模型可能效果更好；主动学习让模型自主选择数据是重要方向。
-   AI系统的分阶段发布（Staged Release）：
    -   背景：GPT-2的强大能力引发了对其潜在滥用（如制造虚假信息）的担忧。
    -   OpenAI的实践：采取分阶段发布策略，先发布小模型，观察影响，逐步开放更大模型。
    -   理由：AI领域正从“童年期”进入“成熟期”，需要更负责任地考虑技术影响。分阶段发布是应对未知风险的一种方式。
    -   协作：需要AI开发者之间建立信任与合作，共同应对挑战。

**VI. 通往通用人工智能（AGI）之路**

-   构建AGI的关键：Ilya猜测是“深度学习 + 少量其它关键思想”。
-   自博弈（Self-play）：可能是关键思想之一。它能产生出乎意料的、创造性的解决方案（如AlphaZero、Dota机器人、捉迷藏智能体），这似乎是AGI应具备的重要特质。
-   模拟（Simulation）：是有用的工具，模拟到现实的迁移（Sim-to-Real）是可能的且在进步（如OpenAI魔方机械手）。迁移能力越强，模拟越有用。
-   具身智能（Embodiment）：拥有身体是有用的（可以学习特定经验），但可能不是必需的（类比：海伦·凯勒）。
-   意识（Consciousness）与自我意识（Self-awareness）：意识难以定义，但基于人类是意识的存在，人工神经网络可能也能够产生意识。自我意识对AGI是有用的。
-   智能的测试：图灵测试？Ilya更看重系统能否避免犯人类不会犯的“愚蠢”错误。克服当前模型所犯的非人类错误将是重要进展。
-   AGI控制与对齐（Alignment）：
    -   可控性：Ilya坚信可以设计出“愿意”被人类控制、以帮助人类福祉为内在驱动力的AGI（类比父母对子女的关爱）。
    -   实现方式：需要研究对齐机制，例如训练一个能理解并内化人类价值观的系统作为AGI的目标函数/价值函数。
    -   权力交接：Ilya认为将AGI的控制权交给更广泛的民主机制（如人类作为“董事会”，AGI作为“CEO”）是理想的，并表示自己会“毫不费力地”放弃对AGI的个人控制权。

**VII. 哲学层面的反思**

-   与AGI的首次对话：会充满好奇地提问，测试其能力边界，并寻求建议。
-   生命的意义：Ilya认为追问“客观意义”可能方向有误。生命的意义在于存在本身是奇迹，应充分利用有限时间，追求价值与享受，减少痛苦。人类的内在驱动（欲望）构成了个体动态的目标函数。
-   关于遗憾、骄傲与幸福：
    -   遗憾：承认有很多决策事后看来可以做得更好，但接受当时已尽力。
    -   骄傲：对取得的成就（如科研突破）感到骄傲和幸运。
    -   幸福：成就并非幸福的源泉。幸福很大程度上来源于看待事物的方式和心态（如感恩、享受当下），以及保持面对不确定性的谦逊。