
# 通用机器人的新时代
- 视频链接：[A New Era for Generalist Robotics: The Rise of Humanoids | NVIDIA GTC 2025](https://www.youtube.com/watch?v=BmD22FNOAY4)
- 官方频道：[NVIDIA Developer](https://www.youtube.com/@NVIDIADeveloper)

## 讲座介绍

内容整理自 NVIDIA GTC 2025 的一场专题讨论，聚焦于正迎来新纪元的人形机器人技术。随着人工智能，特别是基础模型和仿真技术的飞速发展，以及硬件成本的下降和性能的提升，曾经进展缓慢的机器人领域正经历前所未有的加速。本次讨论汇集了来自 1X、Skild AI、Agility Robotics、Boston Dynamics 等领先机器人公司以及 NVIDIA AI 研究部门的负责人，他们分享了各自对于人形机器人崛起的观察与实践。

讨论深入探讨了驱动这一变革的关键因素，包括 AI 模型的进步、数据获取方式的革新（从依赖稀缺的真实世界数据到大规模利用仿真和互联网多模态数据）、硬件的成熟以及“从经验中学习”这一核心理念的转变。各位专家分享了各自公司在模型构建（如追求端到端简洁性与结合传统工具箱的争论）、数据策略（如数据金字塔、多样性重要性、利用人类活动数据）和学习机制方面的独特方法。

同时，讨论也未回避当前面临的严峻挑战，如实现模型在不同机器人硬件上的“跨实体泛化”、硬件与软件协同进化的复杂性、真实世界学习效率低下以及确保安全和赢得社会信任等关键问题。最后，与会者对人形机器人的短期（2-5年）和长期（10-20年）发展进行了展望，描绘了从专用任务到通用智能，乃至机器人加速科学发现和自我改进的未来图景。

## 内容纲要

```
通用机器人新纪元：人形机器人的崛起 | NVIDIA GTC 2025 访谈录
├── I. 引言：人形机器人新时代的到来
│   ├── 主持人开场：强调进展与讨论重要性
│   └── 各公司代表介绍与愿景
│       ├── 1X (Bernt Børnich): 创造劳动力，强调消费先行与在人类生活中学习
│       ├── Skild AI (Deepak Pathak): 构建通用机器人大脑，共享基础模型应对数据稀缺
│       ├── Agility Robotics (Pras Velagapudi): Digit为工作而生，强调真实部署学习
│       ├── Boston Dynamics (Aaron Saunders): 让机器人成为现实，解放人类于“脏累险”工作
│       └── NVIDIA (Jim Fan): Groot项目（机器人大脑基础模型），普及物理AI，开源Groot N1
│
├── II. 机器人领域加速发展的驱动力：为何是现在？
│   ├── 历史背景：AI最古老应用之一，莫拉维克悖论导致进展缓慢
│   └── 关键变化因素
│       ├── AI模型进步：基础模型（推理）、多模态模型（视觉理解）
│       ├── 数据获取与生成：仿真技术（GPU加速）克服数据瓶颈
│       ├── 硬件发展：性能提升、成本下降、零部件商品化、鲁棒性增强
│       ├── 仿真与现实差距缩小 (Sim-to-Real Gap)
│       ├── 核心方法论转变：从控制理论到“从经验中学习”
│       └── 互联网数据的引导作用 (Bootstrapping)
│
├── III. 实现通用人形机器人的核心策略与方法
│   ├── 模型设计哲学
│   │   ├── NVIDIA (Groot): 追求极简端到端（光子到动作）
│   │   └── 普遍观点：平衡端到端学习与传统工具箱（安全、确定性）
│   ├── 数据策略与来源
│   │   ├── NVIDIA (Groot) 数据金字塔：真实数据 -> 仿真数据 -> 互联网/神经仿真数据
│   │   ├── Skild AI: 利用一切数据，包括人类活动视频
│   │   ├── 1X: 强调数据多样性 > 数据量
│   │   └── 通用策略：结合多种来源数据
│   └── 学习机制
│       ├── 从经验中学习 (Learning by Experience)
│       ├── 仿真学习 (Simulation Learning)
│       ├── 真实世界部署学习
│       └── 遥操作：数据收集手段，但有局限性，需更高级接口
│
├── IV. 面临的关键挑战与深入讨论
│   ├── 跨实体泛化 (Cross-Embodiment)
│   │   ├── 问题定义：模型在不同硬件上的泛化能力
│   │   └── 潜在解决方案：多样数据、硬件抽象、标定、领域随机化、历史上下文、自适应学习引擎
│   ├── 硬件与软件的协同进化：任务依赖性，非完全解耦
│   ├── 真实世界学习的效率与“接地”
│   │   ├── 效率瓶颈 vs. 真实反馈
│   │   └── 交互对抗幻觉，但通用“接地”机制是挑战
│   └── 安全性与社会接受度：信任建立、部署考量
│
├── V. 未来展望：机遇与时间线
│   ├── 短期预测 (2-5年)
│   │   ├── 研究“具身智能缩放定律”
│   │   ├── 任务专用/多任务机器人率先商业化
│   │   ├── 建立应用“滩头阵地”，提升社会期望
│   ├── 长期预测 (10-20年+)
│   │   ├── 引发类似电力普及的社会变革（劳动力）
│   │   ├── 机器人加速科学发现
│   │   ├── 机器人实现自我复制与改进 (AutoML for Robotics)
│   │   └── 最终愿景：“一切移动的物体都将自主”
│   └── 普遍共识
│       ├── 高估短期，低估长期
│       ├── 发展路径曲折，需长期投入
│       └── 增量价值逐步显现
│
└── VI. 结语
    └── 主持人总结，说明后续交流形式
```


---

# 通用机器人新纪元：人形机器人的崛起 | NVIDIA GTC 2025 访谈录


## I. 引言：人形机器人新时代的到来

**主持人 (Tiffany Janzen):** [掌声] 大家好，哇，现场观众看起来太棒了。就像Madison刚才说的，我是Tiffany Jansen，今天将是你们的主持人。简单介绍一下我自己，我是Tiffen Tech的创始人。不知道你们怎么样，但我一直期待着这场座谈会。人形机器人近来取得了非常多的进展，能够与这个领域的一些领导者坐下来交流，听取他们的见解，这真是太不可思议了。不仅是为了了解我们现在所处的位置，更是为了了解我们将走向何方。让我们先来一轮自我介绍，从Bernt开始吧。

**Bernt Børnich (1X CEO & 创始人):** 当然。我的名字是Bernt Børnich，我是1X的创始人兼CEO。我们的使命是通过这些安全的、智能的人形机器人创造充裕的劳动力。我们坚信，要真正实现智能，这些机器人需要在我们中间生活和学习。这就是为什么我们认为消费级应用必须先行，这样才能真正体验人类生活的各种细微之处，然后利用这种智能，最终在所有其他垂直领域，如医院、养老护理、零售、工厂、物流等领域，从事有用的劳动。这很令人兴奋。

**Deepak Pathak (Skild AI CEO & 联合创始人):** 大家好，我是Deepak Pathak，Skild AI的CEO兼联合创始人。在Skild，我们正在为机器人构建一个通用的“大脑”。我们的核心理念是，我们可以拥有一个单一的共享模型，因为机器人领域本身就数据稀缺，我们不妨利用所有能从任何平台、任何任务、任何场景中获得的可用数据。可以把它想象成一个大规模的基础模型，可以用于任何机器人、任何硬件、任何任务、任何场景。

**Pras Velagapudi (Agility Robotics CTO):** 我是Pras Velagapudi，Agility Robotics的CTO。在Agility，我们的人形机器人Digit是为工作而生的，我们正在将其引入制造业和物流的应用场景。我们认为，将技术推向市场并从中学习的最佳方式，就是获得真实的客户和真实的部署来完成工作。这就是我们一直专注的事情，让机器人走出实验室，进入劳动力队伍。

**Aaron Saunders (Boston Dynamics CTO):** 我是Aaron Saunders，Boston Dynamics的CTO。在人形机器人变得“酷”之前，我就已经在研究它们了。在Boston Dynamics，我们的使命长期以来一直未变，那就是让机器人成为现实。我们已经交付了几千台机器人，人形机器人是我们最新的发布。我们真正想要的是将一款能够完成真正有用工作的产品推向市场，也就是能够将人们从肮脏、枯燥、危险的工作中解放出来的工作。这是我们长期以来一直在做的事情，我认为还有很多工作要做，但我们对未来的方向感到非常兴奋。

**Jim Fan (NVIDIA 首席研究科学家 / 高级研究经理):** 大家好，我是Jim Fan，我是NVIDIA Gear Lab和Groot项目的联合负责人。Groot是NVIDIA旨在为人形机器人构建基础模型（机器人大脑）的“登月计划”倡议。Groot也代表了我们针对下一代物理AI计算平台的战略。我们的使命同样是普及物理AI。事实上，昨天在Jensen（黄仁勋）的主题演讲中，我们宣布了开源Groot N1模型，这是世界上第一个开源的人形机器人基础模型。它只有20亿参数，但表现超乎其体量。你基本上可以将世界最先进的自主化人形机器人智能掌握在手中。我还想说，就像这个座谈会上的其他人一样，我在机器人技术变得“性感”之前就开始研究它了。今天看到这里座无虚席，我真的非常高兴它今天变得如此性感。非常感谢大家，你们让我今天非常开心。

**主持人 (Tiffany Janzen):** 哦，感谢大家的到来，我知道我们都很兴奋。在我们座谈会之前，我们显然通过一次电话会议。在那次谈话中，我记不清具体是谁了，但有人在会上分享说，机器人是人工智能最古老的应用，而且在历史上，它的发展速度是最慢的。我想说，现在情况不再如此了。那么，是什么改变了呢？

## II. 机器人领域加速发展的驱动力：为何是现在？

**Jim Fan (NVIDIA):** 我想是我在那次电话会议上提出的那个问题吧，是的。嗯，我认为最大的变化是Jensen（黄仁勋）现在开始关注机器人技术了。Jensen有点石成金的本领，对吧？任何他涉足的领域都会指数级增长，我们称之为“Jensen扩展定律”，对吧？玩笑归玩笑，我认为机器人技术是最古老的领域之一，几乎与AI本身存在的时间一样长。机器人如此困难的原因在于“莫拉维克悖论”（Moravec's paradox）。这个悖论指出，对人类来说容易的事情，对机器来说却非常困难，反之亦然。比如我们觉得极难的创造性写作，对机器来说可能并不那么难。这就是为什么像大型语言模型（LLM）、自然语言处理（NLP）、计算机视觉这些领域，如今比机器人技术解决得好得多。所以我们现在正面临这个悖论。

那么现在发生了什么变化？我认为有几个方面：

一是在**模型方面**。由于大型基础模型，如LLM的“ChatGPT时刻”的到来，我们现在有了能够进行推理的模型，以及能够理解计算机视觉的多模态模型，对三维视觉世界的开放词汇理解能力远超以往。这些是解决机器人问题的必要但不充分条件。你必须先解决视觉问题，拥有一个非常好的视觉系统，然后才能谈论拥有通用目的的机器人。所以我认为模型方面正在变得非常好，使我们能够更系统地处理机器人问题。这是第一点。

二是**数据方面**。你知道，不像LLM——我引用Ilya Sutskever的话，他说“互联网是人工智能的化石燃料”。嗯，机器人甚至没有这种“化石燃料”。至少对于LLM，你可以从维基百科下载文本、抓取文本。但我们去哪里从互联网上抓取电机控制数据、抓取所有那些机器人轨迹呢？你根本找不到。所以我们必须生成数据，必须大规模收集数据。我认为仿真技术，特别是GPU加速仿真的出现，确实让这些问题变得更容易处理。因为现在你可以在大约三个小时的计算时间内生成相当于10年训练数据量的数据。这确实使我们超越了数据困境。这是第二点。

三是**硬件方面**。我们这里有一些最杰出公司的创始人，他们创造了我们所见过的最好的机器人硬件。我认为硬件已经变得好得多，也便宜得多。就像今年，我们看到的硬件价格大约在4万美元左右，相当于一辆汽车的价格。而在2001年，NASA建造了Robonaut，最早的主要人形机器人之一，当时的价格是150万美元（2001年美元）。所以它终于变得负担得起，以至于很快会成为主流。

**主持人 (Tiffany Janzen):** Aaron，我很想听听你对此的看法。你在介绍中提到，你在机器人技术变得“酷”之前就已经入行了。那么你认为发生了什么变化？

**Aaron Saunders (Boston Dynamics):** 是的，刚才Jim谈了很多方面，让我试着从中挑选几点来谈谈。我确实认为“仿真到现实”（sim-to-real）差距的缩小是一个重大进展。在很长一段时间里，机器人社区都在努力创建一个既能恰当表示物理现象又计算高效的仿真环境。我们可以创建非常复杂的模型，能够很好地模拟物理世界，但我们无法实时或超实时地运行它们。所以对我来说，最大的变化可能是能够以超实时的方式模拟真实世界的物理现象，这让你能够加速探索仿真的数量，以及如何利用这些仿真来开发新的人工智能。

然后，就是许多零部件的商品化。我想我们可能需要极大地归功于一些邻近行业。消费电子产品开发了电池和摄像头，这些感知技术、观察世界的技术、计算技术……回想起来，即使是10到15年前，大部分机器人内部都塞满了PCB板和电线，电池容量非常小。现在完全变了。我们可以放入大量的计算能力，可以放入微小的传感器，而且它们功耗很低。所以我认为零部件的商品化，并不完全是关于低成本——我知道这是目前的一个焦点——但我认为我们看到机器人创业时代到来的原因，是因为有一个全球供应链，充满了可以像拼图一样组合起来的非常重要的部件。这使得机器人社区从试图设计每一个齿轮的人，提升到了能够将这些部件像拼图一样组合起来的人，基本上可以在更高的层次上运作。所以现在我们有了在智能层面运作的公司，他们在开发应用程序，而不是把同样的资本和精力都花在仅仅制造一个物理机器上。

**Deepak Pathak (Skild AI):** 我可以补充一点Jim最初的观点，我认为你很好地阐述了所有发生的变化。我想补充的是，机器人不仅仅是AI的第一个应用，它**就是**AI本身。如果你看图灵关于AI的原始文献，他谈论AI就是为了机器人。他说，你应该制造能够学习的东西，而不是像制造一个成年人那样；制造一个像孩子一样学习的东西，然后它可以成长。你可以把同一个机器人放在教室里，它会随着时间的推移成长为成年人。这是一个引人入胜的想法，他在1950年代就有了这个想法。因为语言、视觉所有这些东西都很酷，但如果你看看自然界，它们在时间线上出现得远比物理行动晚。例如，我们训练LLM的数据，可能来自过去100年、200年，最多假设1000年。我们训练的数据不会超过1000年。而人类存在的时间远超千年。所以并不是语言导致了智能，而是智能的基础设施早已存在。我们的大脑实际上是通过物理推理进化而来的，这就是为什么机器人的影响如此巨大。你不需要向任何人解释什么是机器人，你能感觉到它，因为我们每天都在做物理任务，每个公司都受到机器人的影响。这就是关键所在。

除了Jim提到的所有因素之外（那些是技术细节，是的），**真正改变的是我们处理机器人的整体方法**。到目前为止，机器人一直是控制理论的领域。可以说直到三四年前，控制理论仍在驱动着机器人技术。对于在这个领域待了很长时间的人来说，他们会知道控制理论并非为机器人而设计。控制理论的鼎盛时期是在二战期间，用于飞机、导弹等。然后因为图灵，机器人的热潮开始了。人们就想，我们用什么呢？好吧，就用那个为飞机导弹建造的控制理论吧。这个方法一直沿用了几十年，长达70年。但这与图灵的初衷不同，不是那种“孩童般的学习”。你不会先教孩子微积分来学习走路，让他们先搞清楚关节运动再学走路。你是通过**经验**来学习的。

所以，**从经验中学习**是现在发生的主要变化。我们现在看到所有的转变都在发生。我是说，Boston Dynamics今天就发布了一个通过经验学习的视频。所以，我会说，从“编程经验”到“从经验中学习”，这是我们思考机器人的方式发生的一个重大转变。

**Bernt Børnich (1X):** 我想就这一点深入谈谈。对我来说，我也是在这个领域待了足够长的时间，经历过经典的控制理论团队。很大一部分的变化其实是**互联网**。想想看，这是一个巨大的人类实验，将近30年的时间里，全世界每个人都在贡献，创造了这个巨大的数据源，使我们能够训练出一个AI，这简直是魔法。现在我们要做的，就是请大家再做一次同样的事情，在接下来的30年里，到处扮演机器人……不，我们不会那么做。但我们拥有了那些数据（指互联网文本、图像等），因此，正是这些数据推动了AI的发展，尽管AI起源于机器人。

对我而言，现在最关键的是，我们如何利用这些现有的数据来**引导**（bootstrap）机器人，使其能够做一些有用的事情。因为一旦到了那个点，你就可以开始在真实世界中学习，而真正的智能正源于此。但你必须先让它达到某种程度的“有用”。比如我说“去冰箱给我拿瓶可乐”，如果机器人有一半的时间能做到，那我们就有了可行的路径。因为现在我们只需要说“这个成功了，那个没成功”，然后需要足够多的重复尝试，它就会在给我拿可乐这件事上变得非常擅长。

我认为这就是我们现在看到的所有这些多模态LLM出现所带来的：你可能无法完全通过这种方法（指仅用现有数据）解决机器人或广义上的智能问题，但我认为，你可以让系统变得**足够有用**，从而能够大规模地创建一个非常高效的**数据飞轮**（data flywheel），这个飞轮不再需要你为机器人的每一个动作进行遥操作。这很可能是通往（如果不是AGI）至少是非常非常有用的机器，甚至可能是通往AGI的路径。我们拭目以待。

**Pras Velagapudi (Agility Robotics):** 我想呼应Aaron的一些评论。为什么机器人技术现在又回来了？AI始于机器人，然后发展到所有其他领域，现在又绕回来了。嗯，机器人技术之所以具有挑战性，有两个原因：一是**硬件很难**，二是**世界是非结构化的**。如果你看看AI和机器人技术是如何演变的，机器人技术的很大一部分一直在处理“硬件很难”的问题：微型化传感器（如MEMS）、构建执行器和驱动技术、储能技术等等。所有这些都必须先解决。甚至像Arduino这样的平台，也普及了人们让物体在现实世界中移动的能力，让人们不必每次都重新发明轮子。

在AI方面，我们基本上是一步步地从解决结构化问题到日益非结构化的问题：从解决查询和提示的问题，到API，到简化的世界模型，再到现在的非结构化世界模型。这个拼图的每一块都在提升AI平台的能力：寻找新的数据摄取方式，借鉴先前结构化方法的最佳实践，然后将其推向下一步——“如果我们去掉一些这些‘训练轮’会怎样？”现在你只是看着自动驾驶汽车传来的视频，或者现在你只是看着机器人摄像头捕捉到的第一视角视频，然后思考这个世界接下来会发生什么。所以我认为，幕后一直有这种逐步解锁的进展在发生，我们只是看到了这种进展最终达到临界点的结果。现在，好了，我们可以去解决与非结构化世界交互这个完整的问题了。

**Bernt Børnich (1X):** 我认为你最后说的那点非常重要，谈论硬件方面发生的变化。也许过去几年发生的最大变化之一是**硬件的鲁棒性**，以及制造出在与真实世界交互时不会损坏的硬件的能力。因为我们所有在机器人领域工作了很长时间的人都知道，如果你每次运行实验都要重建机器人，那么实验会花费相当长的时间。但现在我们在硬件方面确实达到了这样一个程度：我们可以让机器人在真实世界中学习，并安全地与世界互动，而不会损坏自身或环境。这也是这项技术进步的一个必要条件，而这花费了很长时间，这是一个相当困难的问题。

## III. 实现通用人形机器人的核心策略与方法

**主持人 (Tiffany Janzen):** 听了大家的想法，这引出了一个有趣的问题。我认为你们都有非常激动人心且独特的策略和方法。我非常好奇想听听你们对于诸如**人工智能的角色**、从**专用模型**转向**通用模型**，或者你们如何思考像**基础模型的爆炸式增长**这类事情的看法和策略。

**Jim Fan (NVIDIA):** 我或许可以谈谈Groot的策略。我们正在解决一个非常非常困难的问题——为各种不同的人形机器人构建一个通用的“大脑”，不仅仅是一种。我们还希望实现所谓的“跨实体”（cross embodiment）泛化。那么我们如何应对这个问题呢？

我会说有两个主要原则：

原则一：**模型本身我们希望尽可能简单**。我们希望它尽可能地端到端（end-to-end），以至于基本上是“光子到动作”（photons to actions）。也就是说，你从像摄像机那里获取像素输入，然后直接输出连续的浮点数，这些数字本质上就是电机的控制值。这就是模型，端到端的，没有中间步骤，尽可能简单。

为什么这样做是好的呢？因为如果我们看看NLP领域——顺便说一句，NLP是迄今为止被AI解决得极其成功的领域，也许是最成功的——我认为作为机器人专家，我们应该“抄作业”，抄那些已经被证明有效的方法的作业。对于ChatGPT来说，在它出现之前，NLP领域有点混乱，对吧？你有文本摘要、机器翻译、代码生成，它们使用完全不同的数据流水线、训练协议，有时甚至是不同的模型架构，不仅仅是一个模型。然后ChatGPT横空出世，彻底颠覆了一切，因为它简单：它将任何文本映射到任何其他文本，仅此而已。底层是一个Transformer，将一个整数序列映射到另一个整数序列。正因为如此简单，你可以将所有的数据、所有的问题统一到一个模型中。我认为这就是机器人技术应该“抄作业”的地方——让模型尽可能简单。

原则二：**数据流水线实际上会非常复杂**。围绕模型的所有东西都会非常复杂。这是因为对于机器人技术，正如我一开始所说，数据是一个巨大的问题。你无法从YouTube、维基百科下载电机控制数据，你根本找不到。

所以，对于Groot，我们的数据策略可以组织成一个**金字塔**。现在，闭上眼睛，想象一个金字塔。
-   **在顶部**，是**真实机器人数据**。这将是最高质量的，因为没有领域差距（domain gap）。你是通过在真实世界中进行遥操作来收集的。但这必定是相当有限的，扩展性不强，因为我们受到每个机器人每天24小时这个基本物理限制。在原子世界中扩展真的很难。
-   **在金字塔的中间**，是**仿真**发挥作用的地方。我们严重依赖像Isaac Sim这样的物理引擎来大规模生成数据。这些数据可以基于真实世界收集的数据生成，或者像Deepak提到的那样，通过“从经验中学习”来生成。那就是仿真数据。请记住，在NVIDIA成为一家AI公司之前，它是一家图形公司。而图形引擎最擅长什么？物理和渲染。这就是我们的仿真策略。
-   **在金字塔的底部**，我们仍然需要所有那些来自**互联网的多模态数据**。但这次我们使用它的方式有点不同。我们用它来训练**视觉语言模型（VLM）**，这些模型可以成为**视觉-语言-动作模型（VLA）**的基础。VLM是从大量互联网文本、图像、音频等训练出来的。最近，视频生成模型也变得非常好，以至于它们可以成为世界的**神经仿真（neural simulation）**。所以金字塔的最后一层实际上是神经仿真，它超越了传统的图形引擎。通过这些神经仿真，你可以提示一个视频生成模型，并要求它做一些事情，比如“帮我幻想（hallucinate）一个新的机器人轨迹”。视频模型因为在数亿个在线视频上训练，学习物理学得非常好，以至于能够给你提供物理上准确的像素级轨迹。然后你可以运行我们在Groot N1中提出的一种叫做“潜在动作”（Latent Action）的算法，从这些我们称之为机器人“梦境”（dreams）的幻想中提取回那些动作。就像人形机器人梦见电子羊一样，它在做梦，你从中收集那些潜在动作，然后把它们放回这个数据金字塔中。

通过所有这些非常复杂的数据策略，我们将它们**压缩**，压缩成这个干净的产物：从光子到动作。一个20亿参数的模型足以应对广泛的任务。这就是Groot策略的概述。

**Aaron Saunders (Boston Dynamics):** 我认为这描绘了一个非常美好的未来图景：我们有一个简单的大模型——甚至不算太大——它能解决从像素到运动的一切问题。但我认为在此过程中，我们还需要关注所有那些我们必须承担的责任——将产品交付到真实世界中，这些产品需要**确定性**（determinism）。当你需要向客户交付某物时，你需要了解它在意外情况下的行为，你需要考虑功能安全，你需要考虑如果你在现有功能之上添加新功能时它将如何退化（regress）。

所以我认为你指出了一个非常重要的事情，那就是复杂性被推到了**数据**上，以及你收集的数据上。我认为我们正处于构建那个数据集旅程的最初阶段。所以，我想说，我们认为重要的一项策略是，确保你**不要为了追求那个可能非常强大的最终状态而抛弃整个工具箱**。因为在此过程中，我们作为一个社区还有很多事情要做。其中之一就是**维护购买机器人的客户的信任**。我们必须通过应用我们拥有的所有工具来做到这一点。

所以我认为有很多令人兴奋的新能力，我们认为它们将彻底改变机器人技术的格局，它们已经在改变了。但与此同时，我们也需要现实一点，我们有一个包含70年历史的庞大机器人工具箱，其中一些工具对于解决现实世界的问题仍然是正确的工具，特别是当你操作可能伤人的大型、强大机器人时，或者在人周围工作时，你想要维护那种信任，因为一旦你打破了它，就再也无法挽回了。所以，我想说的是，我们需要应用一个庞大的工具箱。

**Bernt Børnich (1X):** 我非常赞同你和Jim的观点。我们很大程度上也属于那个阵营，我们正在制造一个简单的模型——我们还不完全清楚它最终会是什么样子，所以我不会称之为“非常”简单，但相对简单——并且**一切都关乎数据**。如果我们想从早期和晚期LLM的历史中吸取教训，我认为经常被低估的一件事是**多样性（diversity）**的重要性。在LLM历史的初期，有很多公司试图训练一个非常擅长写诗的模型，所以他们用世界上所有最好的诗歌来训练。但这并不真正奏效。因为除非你在那些与写诗毫无关系的、非常多样化的数据上进行训练，否则你无法获得智能，因为**智能来源于多样性**。

我们现在至少在我们的模型中看到，这对于机器人技术显然也是如此。即使在我们现在刚开始的这个非常小的规模下，使用这些微小的数据集，我们实际上更多地受到**多样性的限制**，而不是数据规模的限制。关键在于，你如何获得尽可能多的任务，在尽可能多的不同环境中，最好还带有一些噪声和动态变化，这样你才能理解一个实际任务到底是什么。

我最喜欢的例子是打开洗衣机。当我们走近看到一台洗衣机时，我们会想：“好吧，我们要把衣服放进那个圆洞里，所以我们要试着打开它。”我们会去找把手，如果打不开，也许某个地方有个闩锁，如果还没有，也许我们把旋钮转回零位。我们对洗衣机实际如何工作有很好的理解，所以我们能弄清楚如何使用一台新的。但今天的机器完全没有这种能力，你基本上是在学习如何重复一个动作。

这就是为什么我们真的认为，**让机器人大量地走出去，真正获得那些多样化的数据**是如此重要。这里是我们非常逆向的观点，我认为讨论起来很有趣，那就是为什么我们说这必须发生在**人群中**，必须发生在**家庭**里。**安全性必须是机器固有的东西**，你如何确保机器中的能量不至于大到危险的程度。然后思考我们如何将此与经典的工具箱结合起来。

**Deepak Pathak (Skild AI):** 我想在这里补充一点。与LLM或视觉模型不同，当你在机器人领域谈论“方法”时，总是有两件事：**硬件的方法是什么？软件的方法是什么？** 没有人会问语言模型这个问题，“GPU的方法是什么？”因为Jensen已经解决了。但在机器人领域，这是两个不同的东西，对吧？这是一个主要问题：是否应该只有一种机器人？应该只有1X的机器人，还是下一个机器人？我们应该部署哪种机器人？然后，如果你部署所有的机器人，那么它们的大脑是共享的吗？

我认为这里有两个关键点。
第一点是人类。任何观众都可以上来，给他们一套VR追踪服或手套、VR头显，他们就能控制**任何**机器人。任何机器人。他们不需要知道电机的细节，不需要知道电机如何工作。这已经证明了**一个可以控制任何机器人的大脑是可能存在的**。这是第一个方面。所以你可以使用来自任何地方的数据。

第二点是，外面没有现成的数据，大家都知道。但我们忽略了一种特殊的“机器人”，它就在那里，并且我们有**海量**的关于它的数据。那些“机器人”就是**人类**。我们不是机械机器人，不是由电力驱动的，我们是生物机器人。但归根结底，类似的原理在指导我们。比如你有运动神经元——它们就叫运动神经元；感觉神经元，将信号从你的传感器传到大脑；运动神经元，将信号从大脑传到你的“马达”（肌肉）。

如果我们都同意一个大脑可以存在，并且可以控制所有硬件，那为什么我们要排除生物硬件呢？如果你不排除它，你实际上可以利用**人类活动的人类视频数据**。比如，我们可能没有一个1X机器人在打开冰箱的视频，但人类每天可能开10次冰箱，外面有数万亿个人类这样做的视频。所以，这至少是我们的信念：这是机器人技术非常关键的数据来源之一，关于人类肢体如何运作。你可以实际利用这些知识来推进，当然，这离不开仿真，因为你不能仅仅通过观看就学会操作。但这些东西可以结合在一起。

**Bernt Børnich (1X):** 我非常同意，所有这些数据都极其有用，我们也在使用它。这些数据是必需的。

**Pras Velagapudi (Agility Robotics):** 作为一个遥操作过很多机器人的人，我可以说，当然，人脑在遥操作各种平台方面很出色，但我可以根据经验告诉你，**性能水平并不相同**。硬件绝对会产生影响。当然，我遥操作过1X的机器人，体验很棒。我也遥操作过一些工业机器人，体验并不好。**硬件在其中可能非常重要**，并且确实定义了一些性能特征。我认为需要注意这一点，即性能会有差异，并且确实需要构建合适的硬件，使其具有可控性、合适的传感能力、合适的惯性特性，才能在现实世界中有效。我是说，我们这里有Aaron，他在过去十年里用这个（指Boston Dynamics机器人的动力学表现）震惊了世界，对吧？机器的动力学特性很重要，你可以真切地看到它以不同的方式移动。

**Deepak Pathak (Skild AI):** 一个例子我们这里没有提到，比如达芬奇（Da Vinci）手术机器人。人们用那个机器人做手术，那已经是一家市值超过千亿美元的公司了，他们做的就是通过遥操作。这太神奇了。所以这意味着，没有人否认人脑非常强大，硬件也很重要。所以这些问题有点……这就是为什么机器人总是涉及这两方面。方法可以不同，但最终它们都必须结合在一起。所以不是说一种硬件或另一种硬件，而是……真实世界数据、人类数据、仿真，以及从所有这些中扩展。

**Bernt Børnich (1X):** 我认为这也关乎自下而上（bottom-up）和自上而下（top-down）的方法。因为我们现在谈论的更多是自上而下的控制架构。但我认为自下而上的方法也很有趣，例如，**如何学习灵巧性（dexterity）**？至少我们正在经历的是，在遥操作中学习手内快速灵巧操作，我们不知道如何做到。我们不知道如何构建一个足够快、足够好、并且能真正提供触觉反馈等所有这些东西的遥操作系统。但是**机器人实际上可以很好地学习它**。如果你只给它一堆物体让它玩耍，这是可以学习的。

然后问题就变成了，你如何在遥操作界面上提升接口的层次，基本上是添加一个抽象层。这样你就不再是说“嘿，我要这样捏住抓取”，而更像是**引导机器**完成什么任务，并**允许系统实际学习灵巧性**。

## IV. 面临的关键挑战与深入讨论

**Aaron Saunders (Boston Dynamics):** 我认为当我们试图将大脑与硬件分开时，我们往往忽略了一件事，那就是你**试图完成的任务**。如果你考虑的是一系列物体很小、惯性无关紧要的任务，是的，你可以很大程度上将大脑与身体分开。但我认为现实是，我们想制造这些机器的目的，大多超出了许多人开始时关注的简单的桌面任务。如果你想举起巨大、沉重、复杂的物体，或者你想接触锋利的金属板零件，或者你想处理热的东西——因为你可以把人从制造环境中移走，让他们远离危险，用机器人代替——那么我确实认为**硬件非常重要**。

我认为它必须**协同进化（co-evolve）**。那种认为我们可以完全将一个带有API的良好硬件平台与任何软件大脑断开连接的想法，我认为有时候，这两者需要共同进化。了解你的执行器的质量，比如它有多少摩擦力，对于你能在仿真中多好地表示它可能非常重要。我认为我们需要更多时间，才能完全理解像Groot这样的模型部署在一个A类型的机器人和一个B类型的机器人上会如何表现。因为我认为我们还没有足够的数据点来说明一个模型将部署在所有这些不同类型的机器人上，并且最终行为不会有显著差异。

如果我试图捡起一袋薯片移动并放下，我认为这可能不重要。但如果我试图拾取一个高精度零件并将其组装到另一个高精度孔中，那可能就非常重要了。所以我认为，关于你是否真的能将这两者分开，目前尚无定论（the jury's out），这真的取决于任务。

**Deepak Pathak (Skild AI):** 也可能是反过来的情况：**一个硬件，有很多大脑**。就像NVIDIA，一个硬件平台，很多公司在上面构建大脑。

**Jim Fan (NVIDIA):** 我认为Aaron实际上触及了一个非常有趣的话题，也是一个非常困难的挑战：**跨实体泛化（cross embodiment）**。跨实体泛化对一个模型意味着什么？让我们思考一下我们自己。我认为人类实际上非常擅长跨实体泛化。每当你打开一个视频游戏开始玩时，你实际上就在进行跨实体泛化。比如你在游戏中驾驶汽车，或者扮演一些奇怪的角色，有时甚至是非人类角色。玩了一会儿手柄后，你会感觉到如何控制虚拟游戏中的那个身体，过一会儿你就能玩得非常好。所以人脑实际上非常擅长跨实体泛化。所以我认为这是一个**可解的问题**，我们只需要找到那组合适的参数来实现它。

我同意Aaron的观点，目前谈论完全的零样本（zero-shot）跨实体泛化还为时过早。意思是说，你拿来一个机器人，模型就神奇地工作了——我不这么认为，我们还没到那一步。但总有一天我们会实现的。我认为实现这一点的一种方式是拥有大量不同的机器人硬件，甚至在仿真中拥有更多种类的机器人硬件。

我们之前的研究小组有一个非常有趣的工作，但我会说仍然是探索性的、有点像玩具的工作，叫做**Metamorph**。我们在仿真中程序化地生成了大量简单的机器人，它们有关节连接方式各异，可能看起来像蛇、像蜘蛛，非常奇怪，但我们生成了数千个。然后我们使用一种“机器人语法”来**标记化（tokenize）** 机器人的身体，本质上是将实体本身转换成一个整数序列。一旦我们看到一个整数序列，我们就会想到Transformer，“Attention is All You Need”，对吧？我们看到Transformer，就将Transformer应用于这数千个实体的整个集合。我们发现，你确实能够泛化到第一千零一个实体。但这仍然是一个非常初步的实验，非常早期。

但我确实相信，如果我们能够拥有一种通用的描述语言，并且我们有大量不同类型的真实机器人和仿真机器人，我们可以标记化它们，可以从中生成大量数据，那么所有的实体就变成了这样一个“实体宇宙”（universe of embodiment），一个实体的向量空间。也许一个新的机器人就会落在这个分布之内。

我还想补充一点，这不仅仅是一个智力上的好奇心，它正在成为一个**非常现实的问题**。我想在座的所有硬件公司的创始人都遇到过这个问题：你有不同代际的机器人，你在上一代机器人上收集的数据和训练的模型，无法泛化，或者在你自己公司机器人的V2、V3版本上性能显著下降。实际上，甚至忘了跨代，即使在同一版本的机器人内部，由于制造原因、所有那些微小的缺陷——这是物理世界，它很混乱——由于所有这些混乱性，不同的机器人甚至不能总是完美地复制同一个模型。即使在一代机器人内部，你也存在跨实体问题，更不用说跨代，更不用说跨不同公司和设计了。所以这正在成为一个真正的问题，我认为我们才刚刚触及表面。

**Aaron Saunders (Boston Dynamics):** 老实说，现在（硬件）多样性并不大。如果你看看人形机器人领域，我们基本上都在使用相当相似的东西，它是我们身体的复制品。在Boston Dynamics，我们决定只为我们的夹持器使用三根手指，你知道，这与拥有完全拟人化手的趋势背道而驰。我们发现，人类非常擅长将自己映射到，即使是三根手指上。你可以让一个遥操作员操作一个三指夹持器，在遥操作设备上训练几个小时后，他们基本上能做你用五根手指做的所有事情。

所以我认为这里有很大的探索空间。我认为因为现在每个人都在努力打基础，我们还不够“勇敢”。但我认为，一旦你看到这些泛化能力开始在我们的模型中显现出来，你就会看到人们稍微偏离（拟人化形态），这可能是好事也可能是坏事。我想我们最终可能会得到看起来与人类足够不同以至于令人恐惧的机器人。但我认为仅仅在操纵器内部，就有如此丰富的机会空间。我想Agility的夹持器就与你在其他这些人形机器人上看到的完全不同，但他们仍然能够完成一些相同的任务。所以我认为这将是未来几年一个令人兴奋的话题。

**Deepak Pathak (Skild AI):** Aaron，给我一千个不同的Atlas，我能帮你解决它！

**Aaron Saunders (Boston Dynamics):** 好吧，好，成交。

**主持人 (Tiffany Janzen):** 我感觉你们已经回答了我的下一个问题，那是专门关于硬件的，所以谢谢大家。但我想继续这个话题，因为它确实是一个有趣的挑战，你们都有非常深刻的见解，而且来自独特的视角。你们会说，刚才谈论的——即便是Jim你提到更多关于同一款制造出来的机器人可能表现不同，这取决于具体情况——这是目前硬件方面最大的挑战吗？

**Jim Fan (NVIDIA):** 我认为这绝对是挑战之一。这也促使我们去研究跨实体泛化这条研究路线，研究我们如何弥合这些差距。但我会将这个问题交给在座的所有产品专家。

**Aaron Saunders (Boston Dynamics):** 这又回到了我认为你会发现**其余工具箱的重要性**所在的地方。如果你制造的机器人有非常好的**校准（calibration）** 方法，如果你制造的机器人你知道如何**表征（characterize）**，如果你在**关节级控制（joint level control）**——那些远在AI之下的层面——做了很多扎实的工作，那么我认为其中一些（变异性）问题就不那么严重了。所以我认为，当你有一个无法表征、没有校准、个体差异很大的机器人，然后你只是随便扔给它一个控制器——无论是AI策略还是其他什么——我想你会发现输出有很大的变异性。但我认为你现在可以做很多工作来最小化这个差距。

**Pras Velagapudi (Agility Robotics):** 是的，我认为另一个方面是，将机器人部署到真实世界中，进行制造，看看你遇到了什么样的变异性，你确实能获得很多学习经验，这些经验会反馈到你构建的流程中。一个很好的例子是，Digit有一个完全通过学习得到的**恢复行为（recovery behavior）**。我们一直在真实世界中部署它，它已经用在我们的生产系统上了。我们用来训练它的**领域随机化（domain randomization）**和**数据多样性**，其来源是反馈自我们在真实世界中遇到的情况，以及我们机群中所有Digit的变异性。

结果证明，我们做了如此多的领域随机化，并将策略强化（hardening）得如此之好，以至于当我们将这个策略转移到我们刚刚推出的新机器人——它重了10公斤，框架大得多——这个策略实际上**一次性（one-shot）** 就转移到了这个全新的机器人上，运动学略有不同，有效载荷更重，一切都不同。这是因为我们一直花费所有这些时间来强化和鲁棒化，比如所有仿真到现实的转移，真正理解像脚部接触这样的细节，以及所有这些部分。所以我确实认为，**随着经验的积累，你会更擅长这种跨实体泛化**，并不仅仅是永远注定需要非常仔细地查看机器人的制造序列号。在某种程度上，随着你不断实践，随着你获得真实世界的经验，你会更了解在训练流程中需要捕捉哪些关键因素（levers）。

**Bernt Børnich (1X):** 当你从几百台机器人扩展到几千台时，你就必须面对这个问题，这是别无选择的。当你拥有数千或数十万台机器人时，你不可能为每台机器人调整你的软件栈。所以我认为这只是必须发生的事情。

我有点同意你们两位的观点，但我也非常同意这里关于**校准很重要**，它非常重要。但我认为这实际上非常有趣，也许有点太深入了，但是当你做**领域随机化**时，你实际上在教你的系统什么？你在教它**保守**。你在教它：“哦，如果我不知道这样做会发生什么，我最好还是安全点。”这在某种程度上掩盖了你的动力学特性。所以这真的取决于你想要达到的目标。如果你进行领域随机化，你不会从系统中获得相同的性能，但当然你会得到非常鲁棒的东西。如果你做了非常好的校准，你就可以从系统中榨取更多性能。所以从长远来看，这会很重要。

然后我认为现在有一些极其令人兴奋的工作正在进行中，那就是将**机器人自身的历史（history）添加到模型的上下文中**。对于每一个单独的机器人，你取它一部分运行时间的数据，放入实际模型的历史（上下文）中，然后它在上下文中学习**自己的动力学特性**。这实际上效果惊人地好。我是说，我们…这真的很酷。这有点像…这是我们称之为**RMA（Rapid Motor Adaptation）** 的工作，就是这个想法。

**Deepak Pathak (Skild AI):** 但我想给这个问题一个稍微不同的角度。你无法跨版本更改模型，这是一个大问题。而且期望世界上只有一家公司的一种机器人，这是非常不现实的。就像汽车，有很多汽车公司；手机，有很多手机公司。但对它们来说，甚至对其他所有应用来说，比如有很多NVIDIA生产的GPU，但你有CUDA层，它将你从硬件细节中**抽象**出来。对于操作系统也是如此。那么当涉及到解决机器人问题时，与之等价的是什么呢？

在这里，我想说一个略有不同的观点。对于所有其他领域，由于我们总是被从硬件中抽象出来——无论是视觉还是语言——比如，如果一家新公司要进入，比如AMD或其他公司，他们必须确保其他人可以无缝地在他们的GPU上运行原来在NVIDIA GPU上运行的代码。这是**硬件制造商的负担**，不是软件的负担。

类比到AI，我们正在构建的机器人大脑，**我们不应该构建一个仅仅能在某个机器人上工作的大脑，而应该构建一个能在机器人上适应（adapt）的大脑**。这就是主要的区别。就像人类拥有的不是一个能做很多事情的系统，而是一个**能学会做很多事情的系统**。我们头脑里携带的是一个**学习引擎**（learning engine）。它可以动态学习，就像你现在听到的一切，你都在动态学习和适应。

这将是AI在其他所有领域和在机器人领域的应用方式之间的主要突破性差异。对于机器人技术，我们真正将要部署的是这些**迷你的学习引擎**。它们之所以需要是学习引擎，是因为很多事情会发生。比如，忘了其他人、其他车等等，甚至最基本的，你自己的身体。如果我去健身一小时后，我的手会酸痛。这时我去拿起牙刷甚至一个瓶子，我现在拥有了一个**不同的身体**，因为我的身体现在需要更大的扭矩才能获得与健身前相同的输出。我们的大脑在**动态地适应**这些每时每刻、每分每秒、甚至更长时间尺度上发生的变化。

这就是我认为当这些AI模型部署到机器人上时，与它们在其他任何地方的应用方式相比，主要的不同之处应该是什么，或者将会是什么。在其他任何地方，研究一直是简单的“训练-部署，训练-部署”。你不需要担心适应性，不需要改变，因为NVIDIA在照顾你，随着GPU变得更好，你被照顾得很好；任何新公司进来，你也被照顾得很好。但在机器人领域，这将是不同之处。你将部署**学习引擎**。这就是为什么这是AI的一个与我们迄今为止所见的任何应用都**非常不同**的应用。

**Bernt Børnich (1X):** 但我认为总的来说，这种机器人AI和其他数字AI之间的区别，我同样认为**会消失**。我们现在问“AI能为机器人做什么？”这个问题问得太多了，而我们没有问“**机器人能为AI做什么？**”因为当你真正在现实世界中采取行动，你有一个假设，你采取行动，你观察结果，然后你学习——这就是我们学习的方式。我们看到最近的推理模型，例如，在数学上、在编码上表现得极其出色，因为它们是**可验证的**。你可以去看看：“我做对了吗？”嗯，机器人某种程度上让你能够对**所有事情**都这样做。这就是我们学习的方式。

**Deepak Pathak (Skild AI):** 在这方面我完全同意。另一个例子是**幻觉（hallucination）**。幻觉在LLM中是个大问题。你听说过机器人产生幻觉吗？这不是一个被讨论的话题。我们讨论为什么？因为机器人**不能**产生幻觉。因为如果我要幻想“如果我把这个瓶子从这里推到那里会发生什么？”我可以**直接试一下**。它会掉下去。我能看见。我不需要…我**通过交互来学习**。所以，既然我能交互，**交互就是幻觉的敌人**。因为当你交互时，幻觉就消失了。而当你从被动数据（passive data）中学习时，数据来自维基百科，你无法去验证所有事情——除非是数学或编码，这些领域幻觉问题较少，因为你实际上可以验证答案。

**Bernt Børnich (1X):** 所以会发生的是，我们会得到**多得多**的数据，就像你说的，我们**翻转了金字塔**（flipped the pyramid）——Yuki（LeCun? 不确定具体指谁）不是这么说的吗？我们翻转了金字塔，现在机器人数据变得比互联网数据大得多，我们就能解决我们今天遇到的很多问题。我们只需要更多的GPU。

**Aaron Saunders (Boston Dynamics):** 我认为这绝对是……答案总是这个。这就是我们都在这里的原因，对吧？我认为你**绝对可以让机器人产生幻觉**。它只是以不同的方式表现出来，即机器人预期结果与现实世界中发生的事情之间的**偏差**。现在，这种偏差是可验证的，就像代码生成中的幻觉在无法编译时是可验证的一样。但它表现为，你知道，机器人执行了一个不可行的轨迹，或者…

**Deepak Pathak (Skild AI):** 我的意思是它**可以通过交互消除**。如果你没有交互的能力，它就永远无法消除。比如，你永远无法知道…比如“你住在这个地方吗？”如果我无法验证，我就永远无法纠正我的幻觉。但在机器人技术中，你**大多可以通过交互来纠正**。

**Bernt Børnich (1X):** 我有一个非常好的实际例子，因为我们去年就做了这个。当时我们办公室有个问题，没人放下马桶圈。我们用了我们之前的一款机器人Eve——它有些轮子但仍然非常灵活。我们让它自主地进去检查马桶圈是抬起还是放下。我们在这个任务上运行了GPT-4o，结果是50%对50%，它完全不知道，是随机的。它无法判断马桶圈是抬起还是放下。这有点像个边缘案例，因为它通常在这些事情上表现得相当好。

但我们让机器人去**合上马桶圈**。这是一个自主策略。它会四处走动，检查浴室，如果马桶圈是抬起的，就把它放下来。这非常有趣，我们都觉得很好笑。但这实际上是在**真实世界中闭合了循环（closing the loop）**。现在模型可以得到反馈：“马桶圈是放下的。我知道它是放下的。我把它合上了，我知道它是放下的。而你（模型）告诉我它是抬起的，你错了。”这类似于在其他地方闭合循环，比如我们使用AI与API或编译器等交互。你让它产生一些结果，然后你通过一个验证阶段，再将结果反馈到系统的上下文中。只是在这种情况下，循环闭合稍微慢一些，因为它要通过物理世界。

**Aaron Saunders (Boston Dynamics):** 现在的问题是，我们不知道如何在**通用情况下**做到这一点。我们可以为某个特定任务设计架构，比如马桶圈。现在的问题是，你如何提出这个问题的某种形式化表述，使得你将**所有事情都根植于（grounding）现实世界**？目前还没有人知道如何做到这一点。在真实世界中的学习速率将会**极其缓慢**。我们可以在真实世界中学习这些东西，因为有后果——你掉了东西，重力使它下落，你能判断出发生了不好的事情。但是我们用物理机器人进行探索的速率……这又回到了数据混合的问题上。你可以做这些非常令人兴奋的小事情，但你需要做多少千次或百万次这样的事情，才能获得足够的数据？所以我认为问题仍然是，我们**能否负担得起产生真实世界数据的成本**？

**Deepak Pathak (Skild AI):** 你还有仿真。仿真也是可以交互的。所以我认为是交互数据，你可以两者兼得。

**Aaron Saunders (Boston Dynamics):** 我同意，仿真也需要更多的GPU。

## V. 未来展望：机遇与时间线

**主持人 (Tiffany Janzen):** 好，我知道我们时间快到了。我非常想以这个问题结束，因为我对此非常好奇。在**未来两到五年内**，你认为这个领域将走向何方？我会让这个问题保持模糊，你们可以按自己的想法回答。我想请Bernt先开始。

**Bernt Børnich (1X):** 好的。两到五年，考虑到这个领域目前的速度，这是一个相当大的范围。但让我先“作弊”一下，说我认为需要**十年**时间，这件事才能完全实现。预测十年后会是什么样子很容易，我认为届时我们将经历与几百年前电力普及类似的社会变革。现在我们早上打开电灯时，已经习以为常了。这种情况将发生在数字和物理领域的**劳动力**上。天哪，这将是一个多么有趣的时代。我认为在那样的社会里，我们可以真正专注于那些让我们之所以为人的事情。

**五年**后？我希望我们能达到那个目标。我认为这很有雄心。我们会努力争取。我认为目前没有人知道。我认为这真的取决于**社会接纳机器人的速度**，以及我们**扩大生产规模的速度**。我们现在正处于它变得“有用”的**临界点**。所以，我会说我们现在拥有的产品，举个例子，目前在家庭中是有用的。它不完美，不是说你就不需要自己做任何事了，但它有用而且有趣。然后你可以从那里开始加速。希望它不会像自动驾驶汽车那样，比我们预想的多花十年时间。但我确实认为，**三到五年**内，它将在大多数人中间相当普及。即使不是每个人都拥有机器人，人们也会认识拥有机器人的人，它们将普遍成为社会的一部分，遍及从消费者和家庭到工厂、物流等各个领域。

**Deepak Pathak (Skild AI):** 有一句话说，人们常常**高估短期进展，但低估长期影响**。我想这可能是比尔·盖茨或其他什么人说的。所以，我同样不能（给出精确预测），这是免责声明。但我认为机器人AI与LLM或VLM不同的一个独特之处在于，LLM必须几乎完全解决问题才能真正有用。无论是编码、通用写作还是其他什么，它必须做得非常好。NLP早期也有不错的系统，但直到性能达到非常高的水平，它们才变得有用。

但这对于**机器人AI来说并非如此**。我们**不必完全解决机器人问题，机器人就能变得有用**。这只是想说，即使在今天，已经有成千上万甚至数百万的机器人被部署了。我们很多东西都是由机器人制造的。所以它们已经存在，已经在那里了。

那么这里的关键部分是什么？机器人技术的关键在于**任务的分解**。能够解决所有地方所有任务的机器人，可能还很遥远，对此我不会做任何预测。但我们将开始看到能够解决少数任务、一个任务、两个任务，或者**任务专家型**的机器人。即使是它们也**极其有用**。因为有很多任务，要么很难找到劳动力，要么很难雇佣。我今天和一家公司聊，他们甚至在让退休人员重新工作，因为在他们特定的应用场景中存在劳动力短缺。所以，**专用机器人会来得快得多**，而通用机器人会更远一些。但在机器人领域，**有用性从第一天就开始了**，这与语言模型不同。

**Pras Velagapudi (Agility Robotics):** 这太对了。如果自动驾驶汽车不危险的话，问题在2015年就解决了。你在2015年就可以坐进一辆能带你四处行驶的汽车，而且它表现得相当不错。

我认为挑战的一部分在于，**采纳（adoption）**不仅仅是一个技术问题，它还涉及像**安全**、**社会接受度**等因素。所以在三到五年内，我们可能会看到，在某些领域机器人的数量比我们预期的要多得多，而在另一些领域则少得多。

但我认为重要的一点是，我们确实看到了机器人技术真正从历史上非常**单一用途**，发展到几乎被**期望具备多用途能力**的顶峰。也许不是通用目的，但至少是**多用途**（multi-purpose）。这正在成为人们的期望。我们能够用这些新的基于AI的平台展示的是：“嘿，一件硬件可以有效地做不止一件事。”我认为这是未来三到五年将持续存在的期望，作为人们正在努力构建的新基线（waterline）。你们所有人现在都看到了这一点并认同了，这很棒。因为现在你们将在社会文化层面承载这种期望，并说：“嘿，为什么我不能有一个能在家里做三四件事的机器人？”或者在我的例子中，“为什么我不能有一个能在仓库或物流设施中做五到十件事的机器人？”这应该是理所当然的。我认为真正驱动这一切的是**人们想要这些东西**，这极大地推动了投资和精力投入，以实现这些目标。

**Aaron Saunders (Boston Dynamics):** 当人们问这个问题时，他们真正想要的是具体的答案，比如“我将在某某日期拥有一个机器人，它将能做所有这些事情。”我认为这个问题的真正难点在于，**对于每个人的期望，没有一个统一的标准**。我通常会问的问题是：“我们什么时候会拥有一个对我们来说像**汽车一样有价值**的人形机器人？”我完全不知道。我们的汽车每天在最极端的天气下都能工作，考虑到投入其中的材料和努力，它的成本几乎微不足道。即使是汽车本身，也未必能触及人形机器人可能为我们生活增加的价值。

所以我认为，我也属于认为需要**十年或更长时间**的阵营。我认为这是典型的技术专家的回答。如果你问一个创始人，他们会说明年；如果你问一个技术专家，他们会说大约十年。而“十年”仅仅意味着我们很难具体量化你将拥有什么。

我认为我们应该关注的是**进展的速度**和**滩头阵地（beachheads）在哪里**。在座的每一个团队都在不同的领域建立有意义的滩头阵地。随着时间的推移，这些阵地会扩大，那个空间将从一堆分散的点——比如Agility在仓库解决问题，我们在人们家里部署机器人，我们将致力于汽车工厂——我认为你会看到从每一个这样的滩头阵地开始**增长**。这不会是一夜之间的事情。我不认为在座的任何人能预测五年后的未来，并准确说出我们将处于什么位置。但我认为我们将看到这种增长，很快所有这些领域将开始重叠。

总有一天，我们会拥有自动驾驶汽车。当你回顾那个市场的历史时，你会发现有很多关于他们预测何时拥有自动驾驶汽车的失误的嘲讽。我认为很多嘲讽源于社区中某些成员就其（自动驾驶）会多快到来的声明。但我非常感激我的车有自动车道保持辅助功能，不会撞到前面的车，并且能防止我倒车时撞到东西。所有这些神奇的东西都源于拥有自动驾驶汽车的梦想。哦，顺便说一句，你现在就可以坐进一辆自动驾驶出租车了。是的，它花的时间长了一点。人形机器人也会如此。

我认为只要社区保持兴奋，积极投入，并认识到这是一个**漫长的过程**，我们就能成功。要获得在商业环境中提供价值的**专用机器人**，我认为我们将在未来**一到两年内**实现。Agility已经在向这个领域交付机器人了。当我们让那些机器人完成10、15、20个任务时，那将是在**未来五年**的范畴内。但我们要解决我们想象中的跨所有行业的所有问题，我认为我们需要**继续梦想，继续努力**。这个行业将需要**持续投入能量数十年**，直到我们解决了所有那些边缘案例。

**Jim Fan (NVIDIA):** 我非常喜欢Deepak说的“人们倾向于高估短期，低估长期”。那么让我把它分解为短期和长期。

我认为在**未来两到五年**内，从技术角度来看，我们将能够充分研究**具身智能缩放定律（Embodied Scaling Law）**。我认为大型语言模型中最重要的时刻之一是最初的Chinchilla缩放定律——基本上是那条指数曲线，你投入更多计算，扩展数据量，扩展参数数量，你就会看到智能呈指数级上升。我认为我们目前还没有类似的东西用于机器人技术。因为机器人技术的缩放定律**极其复杂**。你可以在模型层面扩展，可以在硬件机群（真实机器人数据）层面扩展，那么仿真数据的缩放定律呢？互联网数据的缩放定律呢？神经仿真，即神经“梦境”（neural dreams）的缩放定律呢？当你生成大量视频时。我们将能够研究所有这些东西。这样也许，你知道，五年后或者更早，我们屏幕上就会有那张图表，让你确切知道你购买多少GPU，你的机器人会变得多好。我们很快就能定量地回答这个问题，在短期内。

现在，让我们谈谈**20年后**会发生什么。你知道，每当我在实验室待到深夜，机器人又出了些奇怪的故障，我就会想：“啊，太沮丧了。让我想想20年后会发生什么。”然后我就能继续干下去了。

所以，20年后，有几件事情我非常兴奋，我认为它们并不遥远：
一是**机器人加速科学发现**。我有一些生物医学领域的朋友，做一个实验非常耗时、非常费力。所有那些博士生都需要待在实验室里，照看那些老鼠、那些细胞培养皿。如果我们能将所有这些自动化呢？自动化科学研究。那么也许所有的医学研究就不会花费十亿美元了，它们将被规模化，因为我们获得了这个用智能加速物理世界的API。也许那将是Groot第10版或什么的，我希望如此。这是我非常兴奋的一件事。

另一件事是**机器人自动化机器人自身**。为什么我们不能让机器人互相修理呢？我们看到所有那些大型工厂在制造机器人，但是让机器人自己组装下一代机器人怎么样？我认为这根本不是科幻小说。因为实际上在LLM社区——不幸的是，他们又领先我们了——在LLM社区，人们正在研究**AutoML**，意思是，我们能否提示这些LLM进行深度研究，找到下一个最好的Transformer，找到下一个最好的智能架构？人们正在我们说话的此刻积极地做这件事。可能LLM会先解决这个问题，然后我们将“抄作业”，让物理世界也进行这种**递归式自我改进（recursive self-improvement）**。我认为这将会发生，不是在100年后，而是在**20年内**，这绝对会发生。

所以，我将以一个光明的注脚结束。我认为我们这一代人，我们所有人都**生得太晚，没能探索地球；生得太早，无法前往其他星系；我们生得恰逢其时，正好可以解决机器人问题。**

**一切移动的物体都将自主。**

**主持人 (Tiffany Janzen):** [掌声] 我想这是结束这场讨论的最好方式了。非常感谢我们所有的座谈嘉宾，感谢你们的到来，分享你们关于我们现在所处位置以及未来走向的思考。在大家离开之前，请注意一下，我们不进行传统的问答环节，但我们会去取下我们的麦克风，然后回到这里。任何感兴趣的人，欢迎上台来，你们可以直接向座谈嘉宾提问。所以我们现在就下台去取麦克风，稍后回来回答问题。有兴趣的请上台来。 [音乐]

---

# 要点回顾

**I. 引言：人形机器人新时代的到来**

-   主持人开场，强调近期人形机器人领域的显著进步以及本次讨论的重要性。
-   各公司代表介绍：
    -   **1X (Bernt Børnich):** 使命是创造充足的劳动力。认为机器人需先进入消费领域，在人类生活中学习，再将智能应用于医院、养老、零售、工厂、物流等垂直领域。强调安全和与人共存学习。
    -   **Skild AI (Deepak Pathak):** 构建通用的机器人“大脑”（共享基础模型）。核心观点：利用所有可用数据（跨平台、任务、场景）来应对机器人领域数据稀缺问题。
    -   **Agility Robotics (Pras Velagapudi):** 人形机器人Digit专为工作设计（制造业、物流）。强调通过真实客户部署来学习和改进技术。
    -   **Boston Dynamics (Aaron Saunders):** 使命是让机器人成为现实，将人从“脏、累、险”的工作中解放出来。人形机器人是最新产品，致力于开发能做实际有用工作的机器人。
    -   **NVIDIA (Jim Fan):** 领导Groot项目（人形机器人基础模型/大脑），代表下一代物理AI计算平台。使命是普及物理AI，已开源Groot N1模型（世界首个开源人形机器人基础模型）。

**II. 机器人领域加速发展的驱动力：为何是现在？**

-   **历史背景：** 机器人是AI最古老的应用之一，但进展缓慢，主要受限于莫拉维克悖论（对人容易的事对机器难）。
-   **关键变化因素：**
    -   **AI模型进步:**
        -   大型基础模型（如LLM）提供了强大的推理能力。
        *   多模态模型提升了对视觉和三维世界的理解（这是解决机器人的必要条件）。
    -   **数据获取与生成:**
        -   机器人缺乏像LLM那样易于获取的互联网数据（无法直接下载电机控制数据）。
        -   GPU加速仿真技术的发展使得大规模生成高质量训练数据成为可能（例如，几小时计算生成数年数据）。
    -   **硬件发展:**
        -   硬件性能更好、成本更低（当前约$4万 vs 2001年$150万美元），使得大规模部署成为可能。
        -   零部件（电池、相机、传感器、计算单元）得益于消费电子等邻近行业的商品化，提升了集成度和效率。
        -   硬件鲁棒性提高，机器人能在真实世界中安全交互和学习，不易损坏。
    -   **仿真与现实差距缩小 (Sim-to-Real Gap):** 物理仿真越来越精确，且能以超实时速度运行，极大地加速了AI通过仿真进行探索和学习。
    -   **核心方法论转变:** 从传统的控制理论（为飞机、导弹设计）转向“从经验中学习”(Learning by Experience)，更符合智能本质和生物学习方式。
    -   **互联网数据的引导作用:** 利用现有互联网数据（尤其是多模态LLM）引导机器人达到“足够有用”的初始状态，然后通过真实世界交互启动高效的数据飞轮进行学习。

**III. 实现通用人形机器人的核心策略与方法**

-   **模型设计哲学:**
    -   **NVIDIA (Groot):** 追求极简的端到端模型（“光子到动作”，pixels to actions），直接从像素输入映射到电机控制输出，借鉴NLP中简单模型统一多种任务的成功经验。
    -   **普遍观点:** 需要平衡端到端学习与传统机器人工具箱（如标定、控制、安全机制），特别是在需要确定性和可靠性的商业应用中。
-   **数据策略与来源:**
    -   **NVIDIA (Groot) 数据金字塔:**
        -   顶层：高质量但有限的真实机器人数据（遥操作等）。
        -   中层：大规模仿真数据（Isaac Sim等），基于真实数据生成或强化学习。
        -   底层：互联网多模态数据（训练VLM作为VLA基础）和视频生成模型产生的“神经仿真”数据（利用视频模型“梦境”生成新轨迹，通过Latent Action提取动作）。
    -   **Skild AI:** 利用一切可获得的数据，包括人类活动视频数据（将人视为“生物机器人”）。
    -   **1X:** 强调数据**多样性**（不同任务、环境、噪声）比单纯的数据量更重要，是智能涌现的关键。
    -   **通用策略:** 结合真实世界交互数据、仿真数据、人类演示/遥操作数据、互联网数据。
-   **学习机制:**
    -   **从经验中学习:** 机器人通过与环境交互试错来学习。
    -   **仿真学习:** 在仿真环境中进行大规模、快速、安全的学习和策略优化。
    -   **真实世界部署学习:** 将机器人部署到实际场景中，收集数据并反馈迭代（Agility的实践）。
    -   **遥操作 (Teleoperation):** 作为数据收集和引导机器人的手段，但可能难以覆盖所有精细操作（如灵巧手）。需要开发更高级别的交互接口。

**IV. 面临的关键挑战与深入讨论**

-   **跨实体泛化 (Cross-Embodiment):**
    -   **问题:** 如何让一个模型在不同的机器人硬件上（不同公司、不同型号、甚至同型号不同个体、不同代际产品）都能良好工作？这是真实存在的挑战，即使是同一代产品也因制造差异存在性能不一致。
    -   **潜在解决方案:**
        -   收集和利用大量不同类型硬件的数据（真实+仿真）。
        -   硬件抽象化/标记化（如NVIDIA Metamorph的探索）。
        -   利用底层控制、标定、表征来弥补硬件差异。
        -   领域随机化 (Domain Randomization) 提高模型鲁棒性（但也可能使行为保守）。
        -   将机器人自身运行历史作为上下文输入模型（如RMA），使其在线适应自身动力学特性。
        -   部署“学习引擎”而非静态模型，让机器人在运行时自适应。
-   **硬件与软件的协同进化:**
    -   硬件特性（如驱动器、传感器、惯性）对AI性能至关重要，特别是在处理复杂、精密或与人交互的任务时。
    -   大脑（软件）与身体（硬件）可能需要共同设计和演化，而非完全解耦。
-   **真实世界学习的效率与“接地”:**
    -   真实世界学习反馈真实，但速度慢、成本高。
    -   仿真可以加速学习，但存在Sim-to-Real Gap。
    -   交互是解决AI“幻觉”问题的关键：机器人可以通过物理交互验证假设，消除不确定性。挑战在于如何通用化这种物理“接地”(grounding)机制。
-   **安全性与社会接受度:**
    -   确保机器人在与人共存环境中的安全性至关重要。
    -   需要建立用户信任，避免因事故破坏行业发展。
    -   社会对机器人的接受程度也会影响其部署速度和范围。

**V. 未来展望：机遇与时间线**

-   **短期预测 (2-5年内):**
    -   有望厘清“具身智能缩放定律”(Embodied Scaling Laws)，理解投入与产出的关系。
    -   **任务专用型**或**多任务**机器人将率先在特定场景（如物流、制造）实现商业价值，解决劳动力短缺问题。
    -   人形机器人将开始进入社会视野，建立初步的应用“滩头阵地”(beachheads)。
    -   公众对机器人能力的期望将提升（期望具备多任务能力）。
-   **长期预测 (10-20年及更远):**
    -   可能引发类似电力普及的社会变革，深刻影响劳动力结构，让人类更专注于创造性、情感性工作。
    -   机器人将**加速科学发现**（如自动化生物医药实验）。
    -   机器人将实现**自我复制与改进**（机器人制造机器人，类似AutoML）。
    -   最终愿景：“一切移动的物体都将自主”(Everything that moves will be autonomous)。
-   **普遍共识:**
    -   人们倾向于高估短期进展，低估长期影响。
    -   发展路径可能曲折，类似自动驾驶，需要长期投入和耐心。
    -   虽然通用人形机器人完全成熟尚需时日，但其带来的增量价值（如辅助驾驶功能之于完全自动驾驶）会逐步显现。
    -   这是一个激动人心的时代，我们正处在解决机器人这一重大挑战的历史性时刻。