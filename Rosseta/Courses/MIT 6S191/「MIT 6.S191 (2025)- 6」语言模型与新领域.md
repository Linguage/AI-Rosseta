

> - 视频链接：[MIT 6.S191: Language Models and New Frontiers](https://www.youtube.com/watch?v=HLKo4fJx_7k)
 >- 官方：[链接](https://www.youtube.com/@AAmini)


## 内容介绍

本讲座是MIT 6.S191深度学习导论课程的第六讲，主题为“语言模型与新领域”。Ava Amini讲师首先回顾了课程安排和即将到来的重要截止日期，并推荐了微软研究院论坛作为扩展学习的资源。接下来，讲座深入探讨了深度学习的局限性，包括泛化能力、分布外数据处理、数据质量依赖、模型不确定性、对抗样本攻击以及算法偏差等问题，并通过具体案例和实验结果进行了阐释。

随后，讲座将焦点转向深度学习的新领域——生成模型，重点介绍了扩散模型的原理、训练和采样过程，以及其在图像、视频、分子和生物设计等领域的应用。最后，讲座详细讲解了大型语言模型（LLM）的基本概念，包括其定义、训练任务、训练过程、能力和局限性。其中，特别强调了下一token预测、自监督学习、神经网络缩放定律等核心概念，并分析了LLM在不确定性、置信度、幻觉以及逻辑和长期规划方面的挑战。此外，讲座还预告了全新的软件实验，将引导学生亲手微调LLM并构建聊天机器人。


## 内容纲要

```
├── 课程概述与后勤安排
│   ├── 课程介绍及资料
│   ├── T恤发放
│   ├── 课程进度及未来安排
│   │   ├── 已完成的基础讲座
│   │   └── 后续客座讲座安排
│   ├── 软件实验截止日期延长
│   ├── 提案竞赛
│   │   ├── 截止日期
│   │   └── 奖项评选
│   ├── MIT学生获得学分方式
│   │   ├── 提交项目提案
│   │   └── 撰写论文综述
│   └── 推荐资源：微软研究院论坛
├── 深度学习的局限性
│   ├── 泛化能力问题
│   │   └── 标签随机化实验
│   ├── 分布外数据预测问题
│   ├── 数据质量问题
│   │   └── 狗下巴颜色错误案例
│   ├── 不确定性问题
│   │   └── 自动驾驶汽车事故案例
│   ├── 对抗样本问题
│   │   └── 3D打印对抗样本
│   └── 算法偏差问题
├── 生成模型：深度学习的新领域
│   ├── 生成模型概述
│   ├── 扩散模型
│   │   ├── 前向加噪过程
│   │   ├── 反向去噪过程
│   │   ├── 训练过程及损失函数
│   │   └── 采样过程
│   ├── 扩散模型优势
│   └── 扩散模型应用
└── 大型语言模型（LLM）
    ├── LLM定义
    ├── 训练任务：下一token预测
    ├── 训练过程
    │   ├── 分词
    │   ├── 嵌入
    │   ├── 模型输入
    │   └── 损失函数：交叉熵
    ├── 自监督学习
    ├── LLM后训练
    ├── LLM的能力
    ├── LLM的局限性
    │   ├── 不确定性
    │   ├── 置信度
    │   ├── 幻觉
    │   └── 逻辑和长期规划
    ├── 神经网络缩放定律
    └── 新的软件实验：微调LLM构建聊天机器人

```



---
# MIT 6.S191深度学习导论：第六讲 语言模型与新领域

## 课程概述与后勤安排

好的，在我们认为是本课程核心基础讲座的最后一部分中，我们将重点讨论深度学习和人工智能的现状，不仅讨论其局限性，还将讨论一些最活跃、快速发展的领域，以及我们可以将其视为这个广阔领域新前沿的内容。在此之前，我认为在本课程的现阶段，进行一些后勤方面的讲解会很有帮助，我知道我们已经收到了很多关于这方面的问题，所以我们将花一点时间先讨论这些内容。

正如Alexander提到的，我们有赠送精彩课程T恤的优良传统，我们将从明天开始分发它们。如果您有兴趣获得一件，请明天亲自来上课领取。到目前为止，我们的课程已经完成了六个基础讲座中的五个，展望未来，我们将有一系列来自我们杰出行业赞助商的四个客座讲座，涵盖深度学习新前沿的几个不同主题。我们将更详细地介绍一些重要的截止日期，软件实验的截止日期已从明天午夜延长到周五上午11点。此外，最终提案竞赛的幻灯片提交也有重要的截止日期，同样在周五。最后，提案竞赛本身将于周五举行。

就此而言，您可能知道，并且希望您已经从实验一和实验二开始练习，我们有三个很棒的软件实验，让您可以亲身体验我们一直在讨论的概念。所有关于如何提交实验的说明都位于教学大纲和每个实验的notebook上，所以请首先查看这些资源来解答这些类型的问题。

对于MIT的学生，如果要获得本课程的学分，您有两个选择来满足获得课程学分的条件。请注意，提交软件实验不是获得学分的必要条件。您必须提交项目提案并在周五进行展示，您将单独或最多五人一组，开发一个关于深度学习算法或应用的酷炫新想法，并在周五进行展示。同样，所有说明和细节都在教学大纲上。重要的截止日期，请在明天午夜之前提交您的团队，并且教学大纲中链接的幻灯片将在周五晚上10点整完全锁定以进行编辑，因此之后将无法再进行编辑。重要的是，提案竞赛还提供了一个赢得一些精彩奖品的机会，这些奖品将由我和Alexander、我们的助教以及包括来自我们行业赞助商的几位客座评委来评判。获得学分的第二个选择是撰写一篇关于深度学习或人工智能领域最新科学论文的单页评论，这篇评论也将于周五截止，说明在教学大纲上。

好的，如果您一直在享受Alexander和我带来的这些基础讲座，我希望您已经准备好迎接明天和周五来自我们行业赞助商的客座讲座中一些令人兴奋的新内容。我们将有两场精彩的演讲，深入探讨大型语言模型，演讲者分别是来自Google DeepMind的Peter Gowski和来自Liquid AI的Maxim Labon。然后在周四，Doug Blank将告诉我们，在实际应用中部署人工智能的后果是什么？会带来哪些风险？会产生哪些伦理问题？最后，我将从讲师模式转变为分享我自己在人工智能和生物学交叉领域的一些工作。

此外，如果您对您所看到的内容感到兴奋，并且正在寻找新的资源来进一步扩展您的知识，那么我的团队和微软的研究小组以及微软研究院论坛提供了一系列令人惊叹的资源。这些是我们研究人员在各个领域公开的开源演讲，主题涵盖从人工智能的社会技术影响到人工智能如何改变自然科学等各个方面。因此，请花点时间扫描该二维码并注册，以接收有关微软研究院论坛上发布内容的定期更新。

好的，以上就是我们对本讲座的物流旋风式介绍，现在我们可以真正过渡到真正有趣的东西了。


## 深度学习的局限性

到目前为止，在本深度学习导论课程中，我们不仅了解了这些奇妙算法的基础，还开始理解深度学习如何真正彻底改变了如此多不同的领域、研究领域和应用，从自动驾驶汽车的进步到医学和医疗保健的突破、强化学习、生成模型、机器人技术以及一系列其他应用，如自然语言、金融、安全等等。我们的目标是与您分享对深度学习和神经网络模型如何使这些学科取得进步的具体理解。事实上，我们已经看到算法不仅可以将信号、图像、其他感官数据形式的输入数据生成决策，例如预测或分类，还可以进行逆向操作，从我们想要执行的期望行动中学习帮助我们实现目标的策略，例如在强化学习的背景下，以及生成模型的新进展，这些模型直接解决了这个逆问题，能够训练可以生成全新数据实例的模型。但其核心是，无论我们是将数据转化为决策，还是试图对数据本身的分布进行建模，神经网络和深度学习从根本上都可以被认为是函数逼近器。它们是学习这种函数映射或学习捕获概率分布的函数的非常强大的方法。

为了更详细地理解这个概念，我认为回顾深度学习和神经网络中最早的基本理论之一非常有帮助，该理论于1989年提出，这是一个被称为通用逼近定理的定理。它非常简单地指出，仅具有单个隐藏层的神经网络就足以在一定精度或准确度范围内逼近任何函数。在本课程中，我们一直在谈论深度模型，我们将多个神经网络层堆叠在一起，但该定理暂时忽略了这一点，并说，好吧，如果我们只有一层，如果我们相信一个问题可以被描述为从输入到输出的这种映射，那么通用逼近定理指出应该存在某种神经网络来解决这个问题。退一步说，这似乎是一个非常强大的结果，但如果您仔细观察，我们需要考虑几个需要注意的地方。首先，该定理不保证解决此类问题所需的单元数量，即该层中神经元的数量，并且它不提供关于如何实际学习权重的任何方法或保证，这些权重实际上将支持这种神经网络架构，它只是声称并证明存在一个。但是，正如我们在第一讲中看到的那样，梯度下降的过程实际上可能非常非常复杂，因此进行这种优化是一个非常重要的问题。我认为这个定理可以开始说明我们如何平衡我们对深度学习和神经网络的优势以及这些领域炒作和可能出现的潜在局限性的考虑。作为一个集体社区和作为本课程及以后的个人，我认为我们始终需要注意任何技术的强大功能以及随之而来的局限性，因为我们将它们应用于现实世界。因此，在本课程的第一部分，我们将讨论并谈及您所学到的这些算法的一些重要局限性。

我最喜欢的关于这个概念的例子之一来自这篇现在被称为经典的论文，题为“理解深度神经网络需要重新思考泛化”。在这篇论文中，他们做了一个非常优雅的实验，他们从一个数据集ImageNet中获取图像及其标签，您在这里看到的是，他们所做的是，对于这个数据集中的每个图像，不考虑类别，而是单个图像，他们掷出一个k面的骰子，其中k对应于可能的类别总数，基本上根据该随机样本的结果，他们现在为每个单独的图像分配一个全新的标签。这意味着，这些新标签与图像没有语义上的关联，您可能能够在这里观察到，您可以拥有同一类的两个实例，但现在它们被分配了不同的标签，因此这种映射是完全随机的，我们实际上是在尝试完全随机化我们的标签。现在，有了这个重新标记的、重新随机标记的训练集，他们所做的是，他们训练了一个深度神经网络模型来处理这个采样数据，范围从该图最左侧的未修改数据到右侧完全随机分配的类别标签。现在，当他们进行经典测试，测量测试集上的性能时，正如您所料，随着这种标记中随机程度的增加，分类的准确性确实逐渐降低。但真正令人惊讶的是，当他们现在查看训练集上的性能时，他们发现了这一点。无论他们如何随机化标签，模型都能够在训练集上获得接近100％的准确率，这确实指出了与通用逼近定理相关的想法，并将神经网络视为函数逼近器。神经网络可以完美地拟合一个函数，即使该函数具有完全随机的标签，这再次说明了什么是拟合的概念，以及如何实际衡量泛化以及模型在测试集与训练数据上的拟合。因此，为了进一步说明这一点，如果我们以将神经网络理解为函数逼近器的框架来操作，那么通用逼近定理告诉我们的是，它们非常非常擅长执行此任务。在给定一些训练集数据的情况下，我们可以学习该数据的最大似然估计，将一个函数拟合到该数据，这样如果我们给模型一个新的数据点，比如这里的紫色数据点，我们可以使用我们的神经网络来预测该数据点的似然估计。但是，如果我们现在将数据的范围进一步扩展到相对于这些训练示例的分布范围之外，会发生什么？那里没有关于训练数据在这些范围内的样子，泛化的概念是存在的巨大局限性之一。此外，如果我们查看这些分布范围之外的地方，模型没有足够的训练数据，这就引出了一个问题：我们如何实际知道我们的网络不知道什么？当我们考虑这些示例或用例时，我们如何校准我们对神经网络置信度的期望与其性能？我认为这确实指出了深度学习和人工智能的魔力与兴奋之处，有时也可能存在一种误解，认为深度学习基本上是一种直观的艺术，这种炼金术类似于炼金术，您可能有一些您想解决的问题和任务，并且您有一些与该任务相关的数据集。如果我只是针对该任务构建或部署一些AI解决方案或神经网络模型呢？虽然功能非常强大，并且我们对此感到非常兴奋，但实际上可以归结为几个考虑因素：一是该任务是否真的适合通过深度学习解决方案来解决；二是您能够为该任务处理和管理的数据质量如何。深度学习不是某种神奇的曲柄，您可以将任何东西放入该曲柄中并获得神奇的解决方案。有句名言说“垃圾进，垃圾出”，这确实是真的，您的模型只会与其所看到的一样好。

为了更具体地说明这一点，这激发了神经网络最强大和最相关的失效模式之一，并突出了它们在多大程度上依赖于它们所训练的数据质量。因此，让我们使用这个例子，我们有狗的图像，假设我们想将其传递给像CNN这样的架构，我们想训练网络为黑白图像着色，从黑白变为彩色，可能会发生什么？假设我们观察到这个结果，如果您仔细观察，这只狗下巴底部有一个粉红色区域，为什么会这样？

**问：** 为什么狗的下巴是粉红色的？

**答：** 如果我们看一下，看看狗的一些常见姿势或自然状态是什么，我们可以看到很多狗伸出舌头的例子最终可能会导致这种结果。我认为这很好地突出了这些模型正在建立这些内部表示，这些表示本质上与它们在训练中看到的数据相关联。这就提出了一个问题：我们如何构建能够处理它们在训练中可能没有见过的实例的鲁棒解决方案？

臭名昭著且非常悲惨的是，几年前，一辆自动驾驶的汽车发生碰撞，导致驾驶员死亡。事实证明，驾驶员在最近几周内多次报告说，在同一条道路上行驶时，汽车会开始转向并朝最终撞上的障碍物旋转。事实证明，在自动驾驶系统训练的图像中，它缺少那个特定的障碍物，它当时还没有建成，所以汽车遇到了这个实际上是分布范围之外的实例，并导致了碰撞。这是深度学习中不确定性的核心基本概念，正是像这样的失效模式，才真正激发了理解不确定性概念的来源、量化不确定性并利用这些信息来实际（希望）使模型更强大的需求。这在安全关键型应用（如自动驾驶、医学、面部识别、安全和隐私）中以及通常情况下数据集中可能存在不平衡、稀疏性或数据噪声的情况下非常重要。能够可靠地检测和纠正这些不确定性来源非常重要。

要考虑的第三种失效模式是一种非常著名的模式，您可能已经看过它的预览，这就是对抗样本或对抗攻击的概念。这里的想法再次非常优雅和美妙，即如果我们采用某些数据实例，在这种情况下是这座寺庙的图像，并且假设我们现在有一个CNN分类器，它可以很好地将该图像分配为寺庙的高可能性。现在的问题是，我们是否可以对该图像应用一些小的、难以区分的扰动，从而导致我们所说的对抗样本，进而导致CNN模型无法再将此图像识别为寺庙，而是以非常高的概率分配一个完全不同的标签？这些对抗样本背后的核心概念是这种扰动，它在做什么以及它是如何构建的。请记住，当我们使用梯度下降训练神经网络时，我们的任务是根据某个目标函数来改变网络的权重，我们试图优化的是将损失最小化的权重集，由该目标决定。实际上，我们问的是权重的微小变化如何减少我们的损失，我们是否可以朝着这个方向迈出一步来减少损失？重要的是，更改的是固定图像输入 X 和固定标签 Y 的权重。在对抗样本或对抗攻击中，问题有点反过来了，现在的问题是，我们如何修改输入图像或输入实例，以增加网络预测中的错误？因此，与其扰动权重以最小化损失目标，不如尝试学习对输入的扰动，以对最终决策产生对抗性影响。这实际上可以在现实世界中物理实现。几年前，麻省理工学院的一群学生将对抗样本的概念带入了3D物理领域，他们实际上使用3D打印来合成现实生活中的对抗样本，这些样本可以欺骗计算机视觉模型。除此之外，我认为对抗的概念在概念上非常重要，在实践中也非常重要。反过来，这些关于数据不确定性重要性的集体主题指出了我们作为人工智能部署者和开发人员的责任方面的考虑因素。正如您在课程的软件实验中可能已经看到的那样，算法偏差的概念也非常重要。算法如何延续当今我们世界中存在的文化和社会偏见，并且这些偏见固有地体现在这些算法所训练的数据中？因此，当然这不是深度学习和神经网络所有局限性和注意事项的详尽列表，但希望这些关于偏差和不确定性的概念能够触及其中的一些核心注意事项。我认为，作为技术专家和科学家，局限性为发展提供了机会，我希望这也激励你们所有人走出去，继续扩展新的前沿，自己解决其中一些悬而未决的问题。

因此，在演讲的剩余时间里，我将重点介绍正在进行的一些相关工作，并介绍人工智能和深度学习中的一些前沿新领域。正如您所见，外推和泛化的概念是深度学习的一个非常核心的原则，如今我们已经看到了基础模型和生成模型的概念，它们有望以纯数据驱动的方式实现真正强大的泛化。我认为这非常令人兴奋，并且是一种非常引人注目的方式来证明外推和泛化能力如何由于这些基础模型而呈指数级增长。因此，在本演讲中，我们将真正关注的前沿是生成模型，我们在第四讲中看到了这一点，即对数据分布进行建模以扩展泛化能力的原则。因此，在新前沿部分的第一部分，我们将进一步关注并深入探讨最近引入的一类新的生成模型，称为扩散模型。


## 生成模型：深度学习的新领域

如果您回顾昨天关于生成模型的讲座，我们讨论了生成模型的两个基础起点：VAE 和 GAN。然而，正如一些问题开始提出的那样，并且我们能够在课后进行讨论，这些模型有一些需要注意的关键局限性。首先，它们往往会坍缩成产生我们所说的均值或模式坍缩的重复实例，这意味着在面部图像生成的例子中，您将导致模式坍缩，导致模型仅产生与平均面孔非常接近的东西。这与难以生成多样化样本和外推分布范围之外密切相关。此外，像 GAN 这样的模型可能非常难以训练，并且训练过程不稳定且效率低下。因此，稳定性、生成质量和生成新颖性的这些挑战真正导致了新的方法学进步，这些进步正面解决了这些问题。

一种非常突出的生成模型方法，尤其是在图像和视频领域，是称为扩散模型的框架。如果您已经尝试并使用了一些领先的文本到图像生成系统，那么驱动图像生成的主干生成模型通常是扩散模型。我认为扩散模型非常非常令人兴奋，因为它们背后有一个美妙而直观的想法，这实际上导致了它们能够产生的生成质量非常高。因此，当我们学习 VAE 和 GAN 时，生成图像之类样本的方法是我们所说的单次生成。VAE 或 GAN 试图学习从某种压缩数据表示（如潜在空间或 GAN 情况下的随机噪声分布）到在原始数据空间中生成图像或实例的映射。扩散模型的工作原理从根本上不同，因为它们不是试图一次性完成此操作，而是尝试通过反复去除噪声以迭代方式细化生成过程来迭代地生成新样本。这意味着学习任务通过分解成这些迭代块而得到有效简化，这样最终结果是我们的样本生成质量最终会好得多。

那么让我们看一下扩散模型是如何工作的。扩散模型背后的核心思想是扩散过程的概念，即迭代地向源数据添加噪声以创建训练实例，然后训练我们的神经网络学习如何选择性地、迭代地逐步消除噪声。为了说明这是如何实现的，让我们使用图像示例。假设我们有一个像这样的训练数据实例，在扩散模型中，我们有所谓的前向过程，一个前向加噪过程，我们获取我们的数据实例并逐步地、递增地向实例添加随机噪声，慢慢消除数据中的细节，直到我们达到纯随机噪声的终点。现在，这些单独的实例仅相隔一步的噪声添加。然后，我们转向实际训练神经网络的过程，神经网络学习的是反向去噪过程。加噪过程为我们提供了这些时间步长，这些时间步长越来越嘈杂。现在，任务是给定时间步长 t 的图像或实例，我们能否学习一个神经网络来估计先前时间步长中噪声略小于它所看到的图像？因此，在这里，我们试图学习一个神经网络来执行这种精确的去噪估计。给定 t 处的图像，我们如何才能到达前一个 t-1？我们如何训练这样一个网络来完成这项任务？再次记住，我们正在尝试比较这些成对的实例，它们的区别仅在于随机噪声的一步。关于我们如何实际制定损失或目标来训练此模型，有什么想法吗？

**问：** 如何定义训练扩散模型的损失函数？

**答：** 是的，这个想法是比较先前状态的图像，具体来说，我们如何定义它？假设我们有图像... ...我的问题是如何定义损失？ 是的，我们如何定义损失？

**答：** 均方误差。

**答：** 均方误差，是的，像这样简单的东西。它是比较这两个来实际估计噪声本身，因为这两个实例之间的误差实际上是噪声造成的。事实证明，这实际上是一种非常有效的方法来训练这些类型的模型，有效地学习训练神经网络来学习这些噪声差异本身。

现在，这就是关于如何训练扩散模型的核心概念。训练完成后，您可以使用训练好的模型进行采样以生成全新的实例。我们进行采样的方式，生成一个全新的样本，是从随机噪声开始，然后我们使用我们训练好的神经网络，其权重已更新，经过训练可以预测这些残差噪声差异。它所做的是，它从这个初始状态开始采样新的、噪声逐渐减少的实例，并且这个过程重复进行。随着这种去噪迭代地发生，我们可以看到数据在我们重复这个采样过程时开始回升，直到最后，在这个反向去噪过程的最后时间步长，我们回到了我们原来的数据空间，并且我们在这个空间中生成了一个全新的实例。

总而言之，在训练扩散模型时，您试图学习一个神经网络来预测这个去噪过程，一旦您训练好了，您就可以从训练好的模型中采样以生成全新的实例。这种方法的强大之处在于，从随机噪声开始，我们能够封装最大程度的可变性，但通过比较这些迭代步骤，我们将学习任务分解为实际高效且有效训练的内容。我们可以通过像这样的扩散过程生成非常高质量和高保真的样本，这些是由扩散模型生成的实际实例。真正令人惊讶的是，从完全不同的随机噪声实例开始，最终会产生非常多样化且非常不同的采样图像。这再次与您能够在起始状态封装多少可变性的概念有关。

正如我所提到的，扩散模型是您可能已经看到并试验过的许多这些文本到图像模型和平台的图像生成管道的基础。我认为这通过这些示例真正地体现出来，在这些示例中，您可以看到这些生成的质量和保真度相对于图像本身以及它与输入提示的匹配程度非常高。

扩散模型不仅在图像、视频或类似领域变得非常强大，事实上，在自然科学和生命科学中，我们在用于分子设计和生物设计的扩散模型方面取得了巨大的进步。在星期五，我将分享更多关于这些方法如何工作以及我们能够在此应用中实现的功能的信息。好的，这让我们对最先进的图像生成和其他模态生成生成模型有了一个基本了解。在本讲座的剩余时间里，我们将进入大型语言模型的另一个新前沿，并为您提供LLM基本概念的强大入门知识，为明天的客座讲座以及今天发布的全新软件实验做好准备。


## 大型语言模型（LLM）

我认为现在已经不是什么秘密了，大型语言模型在过去几年中真正腾飞，并且正在彻底改变我们日常生活的许多方面。但我非常热衷于技术，不仅是技术本身，还包括理解我所使用和交互的技术的基本原理。因此，我希望传达的是关于像支持 ChatGPT 的 GPT 这样的 LLM 如何工作以及它们为什么以这种方式工作的背景知识。有了这些知识，希望能够为您提供理解这些模型的功能及其局限性的工具。

那么，从根本上说，什么是 LLM？在第一天，我们从定义人工智能和深度学习的定义开始。LLM 或大型语言模型非常简单，它们是非常非常大的深度神经网络，经过大量文本数据的训练。我们可以这样理解，这些数据集非常广泛，非常不可知，并且一开始实际上是未注释的。为了训练像 GPT 这样的大型语言模型，正如我们开始谈到的一样，需要以特定方式处理此数据集并将其输入模型。然后我们必须定义一个任务，一个学习任务和一个我们想要训练模型的目标。现在，有了这种规模的数据，它不一定是，并且将它拟合到经典的监督学习问题中是不可行的，在经典的监督学习问题中，对于每个数据实例，我们都有一些定义的标签，而我们的神经网络任务是学习数据到标签的映射。相反，这些 LLM 背后的突破和核心思想是使用数据本身来定义任务。一个非常常见的任务，它驱动这些模型，事实上也是驱动 GPT 的任务，是一个非常简单的任务，我们在第一天也看到了。给定一个句子中的一系列块或单词，预测语言建模中的下一个单词或下一个块。这些块通常被称为标记，任务被称为下一个标记预测。给定一系列标记，预测下一个标记，我们将根据模型在此下一个标记预测任务中的表现来更新我们的模型参数（即我们神经网络中的权重）。

这是如何工作的？为了分解它，希望现在这些概念也能从序列建模的讲座中回顾起来。像 GPT 这样的 LLM 的训练方式是获取句子形式的原始文本，例如，第一步是将该文本分成块，并通过称为标记化的过程以数字方式表示它。这些标记被嵌入到数字编码中，并作为输入提供给 LLM。下一个标记预测任务很简单，如下所示：给定一组标记，我们想要预测什么是最可能的下一个标记，估计下一个标记在整个词汇表或所有可能标记空间上的概率。

非常具体地看一下，我们可以做的是实际计算下一个可能标记的分布上的概率，并使用估计概率的信号来训练模型。您可以认识到的美妙之处在于，这实际上相当于一个分类任务。通过计算这些下一个标记概率与真实下一个标记的交叉熵损失，我们能够向模型提供一个信号，以学习如何计算这个下一个标记预测任务。这里的妙处在于，这就是我们所说的自监督信号，我们正在使用数据本身来定义一个信号来训练模型。同样，我们可以使用一些非常简单的东西，比如交叉熵损失，来向模型传达信号。现在，通过在非常大且广泛的数据集上执行这个非常直观的下一个标记预测任务，模型可以学习构成人类语言等复杂事物的基本模式。

现在，当我们通过下一个标记预测任务训练模型后，在部署时，您能够以这种方式进行交互，您可以提示模型，现在可以生成响应。但在实践中，在 LLM 后训练中，实际上需要几个步骤才能从下一个标记预测任务过渡到实际可以用作聊天机器人并可以合理地与之交互的东西。在明天的 Liquid AI 讲座中，您将听到世界上 LLM 后训练方面的专家之一讲解此管道的核心组件以及此处需要考虑的因素。

这种方法为当今的语言模型解锁的功能在知识检索、文本生成等方面确实非常强大，这种对语言的掌握确实非常出色。但是，在部署 LLM 方面仍然存在一些关键的局限性，以及它们仍然难以应对的地方。首先是我们之前在本讲座中介绍的不确定性和置信度的概念。我们仍在非常积极地研究如何可靠地量化像 LLM 这样的大型模型在这些类型场景中的鲁棒性和置信度，以便我们能够可靠地识别我们所说的幻觉，即模型可能产生听起来非常合理但实际上没有现实依据的生成内容，并利用这种理解来考虑当这些 AI 系统与人类和应用程序交互时，我们应该在这些 AI 系统上部署哪些模型级别的防护措施。

最后，语言建模和这些 AI 模型中一个非常突出且活跃的研究领域是逻辑和长期规划的概念，这样模型就可以超越对自然语言的掌握，并泛化到非常复杂的推理和规划类型的任务。尽管如此，我们在像 GPT 及其后的模型中看到的许多突破都来自于观察结果，这些观察结果表明，随着模型规模的扩大以及数据集规模的扩大，这些 LLM 可以获得这些新的涌现能力。神经缩放定律中有一些开创性的观察结果指出，随着我们扩展这些模型的规模以及它们训练的时长和程度，我们可以看到这些模型在它们可以执行和实现的任务方面的能力发生了阶跃变化。

这些概念现在变得非常重要和严肃，当我们考虑基础模型的功能以及我们如何朝着我们可以将其视为真正人工智能的目标越来越近时。在本课程开始时，我们谈到了什么是智能，即获取信息、推理信息并利用信息来指导未来决策的能力。我认为我们的学习流程并不局限于只能解决我们已经看过训练示例的任务，我们能够学习任务背后的概念，这些概念使我们能够加快学习、泛化和创造性地思考我们关心的新领域或新领域。随着我们在生成式 AI 方面看到这些新的进展，它激发了我们自己对人类能力与这些模型的能力和局限性之间的联系和区别的深刻思考。此外，与任何技术一样，人工智能只是一种技术，我们将其创造为一种我们可以使用和部署的技术和工具。我鼓励大家不仅要思考人类智能和人工智能之间的相对异同，还要思考如何最大限度地利用这些工具作为你们自己工作和个人学习和创造旅程中的工具。

我将以这一点留给大家思考和冥想，我鼓励你们彼此之间进一步讨论。我仍然想强调并非常兴奋地宣布，LLM 的这些主题和概念（我刚刚与你们分享的）可以让你们获得亲身实践经验，实际试验和微调 LLM。非常令人兴奋的是，我们推出了一个全新的软件实验，以前从未有过，你们是第一个可以使用这个软件实验的班级，在这个实验中，你们将自己微调一个 LLM 作为聊天机器人，并尝试几种不同的有趣风格，并尝试对其进行实验以优化聊天机器人的性能。希望你们做到这一点，你们不要尝试这一点，你们要做到这一点。这是该软件实验中即将发生的事情的预览。感谢大家的关注，我们将结束，非常感谢大家。


---
# 要点回顾

**课程概述与后勤安排**

- MIT 6.S191深度学习导论课程第六讲：语言模型与新领域。
- 课程相关资料：http://introtodeeplearning.com
- 课程T恤将于次日线下分发。
- 课程已完成五分之六的基础讲座，后续有四场客座讲座。
- 软件实验截止日期延长至周五上午11点。
- 幻灯片提交和提案竞赛截止日期为周五。
- 提案竞赛将于周五举行，奖项将由讲师、助教和客座评委评选。
- MIT学生获得学分的两种方式：提交项目提案并展示，或撰写一篇深度学习/AI相关论文的单页综述，截止日期均为周五。
- 后续客座讲座主题：大型语言模型、AI部署的风险和伦理问题、AI与生物学的交叉应用。
- 推荐资源：微软研究院论坛（Microsoft Research Forum）。

**深度学习的局限性**

- 深度学习模型的泛化能力：即使标签随机化，模型仍能完美拟合训练数据，凸显了泛化能力的重要性。
- 分布外数据：模型对分布外数据的预测缺乏保证，需要关注模型的置信度校准。
- 数据质量：深度学习模型依赖于高质量数据，“垃圾进，垃圾出”。示例：由于训练数据中狗伸舌头的图片较多，导致模型将狗下巴颜色错误地预测为粉色。
- 不确定性：模型无法识别自身不知道的内容，自动驾驶汽车事故案例凸显了这一点，需要量化和理解模型的不确定性。
- 对抗样本：对输入进行微小扰动即可欺骗模型，例如3D打印的对抗样本。
- 算法偏差：算法可能延续数据中存在的文化和社会偏见。

**生成模型：深度学习的新领域**

- 生成模型：学习数据分布以实现更强大的泛化能力。
- 扩散模型：一种新的生成模型，通过迭代去噪来生成样本。
  - 前向过程：逐步向数据添加噪声，直至纯随机噪声。
  - 反向过程：训练神经网络逐步去除噪声，恢复原始数据。
  - 训练：使用均方误差等损失函数比较去噪结果与真实数据。
  - 采样：从随机噪声开始，迭代去噪生成新样本。
- 扩散模型的优势：生成高质量、高保真度、多样化的样本。
- 应用：图像生成、视频生成、分子设计、生物设计等。

**大型语言模型（LLM）**

- LLM：训练于大规模文本数据上的大型深度神经网络。
- 训练任务：下一token预测（next token prediction），即根据已有的token序列预测下一个token。
- 训练过程：
  - 分词（Tokenization）：将文本分割成token。
  - 嵌入（Embedding）：将token转换为数值表示。
  - 模型输入：将嵌入向量输入LLM。
  - 损失函数：使用交叉熵损失函数评估模型预测的概率分布与真实下一个token的差距。
- 自监督学习：利用数据本身定义训练任务和信号。
- LLM后训练：将下一token预测模型转换为可交互的聊天机器人。
- LLM的能力：知识检索、文本生成等。
- LLM的局限性：不确定性、置信度、幻觉、逻辑和长期规划能力。
- 神经网络缩放定律：模型规模和训练数据量越大，LLM的能力越强。


**人工智能与人类智能**

-  人工智能是工具，需要思考如何利用其优势。
-  思考人工智能与人类智能的异同。
-  新的软件实验：微调LLM构建聊天机器人。
